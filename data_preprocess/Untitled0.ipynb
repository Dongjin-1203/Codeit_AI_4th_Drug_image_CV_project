{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8uPUU5mqxaBM4OnuO/ffS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxZZGQjNw_pO","executionInfo":{"status":"ok","timestamp":1757577238415,"user_tz":-540,"elapsed":18331,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"efe4f3a6-8a30-4644-b3c8-e4341f8a9837"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 1. ê¸°ì¡´ ë¦¬í¬ì§€í† ë¦¬ í´ë”ë¡œ ì´ë™\n","import os\n","os.chdir('/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project')"],"metadata":{"id":"V06zTpKMw-ai","executionInfo":{"status":"ok","timestamp":1757577242003,"user_tz":-540,"elapsed":313,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eF1ejIhlwoWd","executionInfo":{"status":"ok","timestamp":1757577926906,"user_tz":-540,"elapsed":172,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"f0ea8f06-62b4-4664-c6b4-5a6fc45d803e"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“– ì‚¬ìš©ë²• (COCO í¬ë§· ì…ë ¥):\n","quick_preprocess_prototype_annotations()  # í”„ë¡œí† íƒ€ì… COCO ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬\n","quick_preprocess_dev_annotations()        # ê°œë°œìš© COCO ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬\n","preprocess_coco_annotations(input_path, output_path)  # ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬\n","ğŸ” ì‚¬ì „ ë””ë²„ê¹…...\n","ğŸ” COCO íŒŒì¼ ë””ë²„ê¹…...\n","1ï¸âƒ£ ë°œê²¬ëœ JSON íŒŒì¼: 0ê°œ\n","âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\n","âŒ ë””ë²„ê¹… ì‹¤íŒ¨. ì „ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n"]}],"source":["\"\"\"\n","ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬ MVP (3ë‹¨ê³„) - COCO í¬ë§· ì…ë ¥ ë²„ì „\n","ì½”ë© í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¸°ì´ˆì ì¸ ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬ ì½”ë“œ\n","\n","3ë‹¨ê³„: ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬ (ì›ë³¸: COCO í¬ë§·)\n","- COCO í¬ë§· JSON íŒŒì¼ ì½ê¸°\n","- ì¢Œí‘œ ì‹œìŠ¤í…œ ì •ê·œí™” (ì ˆëŒ€ â†’ ìƒëŒ€ ì¢Œí‘œ)\n","- ë¼ë²¨ ì¸ì½”ë”© (category_id ë§¤í•‘)\n","- ì–´ë…¸í…Œì´ì…˜ í¬ë§· ë³€í™˜ (COCO â†’ YOLO, Pascal VOC)\n","- ê³„ì¸µì  ë¼ë²¨ë§ íŒŒì‹±\n","- ë°ì´í„° ê²€ì¦ ë° í†µê³„\n","\"\"\"\n","\n","import os\n","import json\n","import glob\n","import csv\n","from collections import defaultdict, Counter\n","import pandas as pd\n","\n","def parse_pill_code(filename):\n","    \"\"\"\n","    íŒŒì¼ëª…ì—ì„œ ì•Œì•½ ì½”ë“œ ì¶”ì¶œ ë° íŒŒì‹±\n","\n","    Args:\n","        filename: íŒŒì¼ëª… (ì˜ˆ: K-003544-010221-016551-027926_0_2_0_2_70_000_200.png)\n","\n","    Returns:\n","        dict: íŒŒì‹±ëœ ì•Œì•½ ì½”ë“œ ì •ë³´\n","    \"\"\"\n","    try:\n","        # í™•ì¥ì ì œê±°\n","        name_without_ext = filename.replace('.png', '').replace('.json', '')\n","\n","        # '_' ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  (ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ì•Œì•½ ì½”ë“œ)\n","        parts = name_without_ext.split('_')\n","        pill_code_part = parts[0]\n","\n","        # '-' ê¸°ì¤€ìœ¼ë¡œ ì•Œì•½ ì½”ë“œ ë¶„í• \n","        code_parts = pill_code_part.split('-')\n","\n","        if len(code_parts) >= 4:\n","            return {\n","                'full_code': pill_code_part,\n","                'prefix': code_parts[0],  # K\n","                'code1': code_parts[1],   # 003544\n","                'code2': code_parts[2],   # 010221\n","                'code3': code_parts[3],   # 016551\n","                'code4': code_parts[4] if len(code_parts) > 4 else None,  # 027926\n","                'is_valid': True\n","            }\n","        else:\n","            return {\n","                'full_code': pill_code_part,\n","                'prefix': None,\n","                'code1': None,\n","                'code2': None,\n","                'code3': None,\n","                'code4': None,\n","                'is_valid': False\n","            }\n","\n","    except Exception as e:\n","        return {\n","            'full_code': filename,\n","            'prefix': None,\n","            'code1': None,\n","            'code2': None,\n","            'code3': None,\n","            'code4': None,\n","            'is_valid': False,\n","            'error': str(e)\n","        }\n","\n","def read_coco_annotation(annotation_path):\n","    \"\"\"\n","    COCO í¬ë§· JSON íŒŒì¼ ì½ê¸°\n","\n","    Args:\n","        annotation_path: COCO JSON íŒŒì¼ ê²½ë¡œ\n","\n","    Returns:\n","        dict: COCO ë°ì´í„° ë˜ëŠ” ì—ëŸ¬ ì •ë³´\n","    \"\"\"\n","    try:\n","        with open(annotation_path, 'r', encoding='utf-8') as f:\n","            coco_data = json.load(f)\n","\n","        # COCO í¬ë§· ê²€ì¦\n","        required_keys = ['images', 'annotations', 'categories']\n","        missing_keys = [key for key in required_keys if key not in coco_data]\n","\n","        if missing_keys:\n","            return {\n","                'status': 'error',\n","                'error': f'COCO í¬ë§· í‚¤ ëˆ„ë½: {missing_keys}',\n","                'data': None\n","            }\n","\n","        return {\n","            'status': 'success',\n","            'data': coco_data,\n","            'num_images': len(coco_data['images']),\n","            'num_annotations': len(coco_data['annotations']),\n","            'num_categories': len(coco_data['categories'])\n","        }\n","\n","    except json.JSONDecodeError as e:\n","        return {\n","            'status': 'error',\n","            'error': f'JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}',\n","            'data': None\n","        }\n","    except Exception as e:\n","        return {\n","            'status': 'error',\n","            'error': f'íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}',\n","            'data': None\n","        }\n","\n","def create_category_mapping_from_coco(coco_data):\n","    \"\"\"\n","    COCO ë°ì´í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ìƒì„±\n","\n","    Args:\n","        coco_data: COCO í¬ë§· ë°ì´í„°\n","\n","    Returns:\n","        dict: ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ë³´\n","    \"\"\"\n","    print(\"ğŸ·ï¸ COCO ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ìƒì„± ì¤‘...\")\n","\n","    categories = coco_data['categories']\n","\n","    # ì¹´í…Œê³ ë¦¬ ID â†’ ì´ë¦„ ë§¤í•‘\n","    id_to_name = {cat['id']: cat['name'] for cat in categories}\n","    name_to_id = {cat['name']: cat['id'] for cat in categories}\n","\n","    # ì•Œì•½ ì½”ë“œ ê¸°ë°˜ ìƒˆë¡œìš´ ë§¤í•‘ ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)\n","    pill_codes = set()\n","\n","    # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ ì•Œì•½ ì½”ë“œ ì¶”ì¶œ\n","    for image_info in coco_data['images']:\n","        filename = image_info['file_name']\n","        parsed = parse_pill_code(filename)\n","        if parsed['is_valid']:\n","            pill_codes.add(parsed['full_code'])\n","\n","    # ì •ë ¬ëœ ì•Œì•½ ì½”ë“œ ë¦¬ìŠ¤íŠ¸\n","    sorted_pill_codes = sorted(list(pill_codes))\n","\n","    # ìƒˆë¡œìš´ ID ë§¤í•‘ (0ë¶€í„° ì‹œì‘)\n","    new_code_to_id = {code: idx for idx, code in enumerate(sorted_pill_codes)}\n","    new_id_to_code = {idx: code for code, idx in new_code_to_id.items()}\n","\n","    mapping_info = {\n","        'original_coco': {\n","            'id_to_name': id_to_name,\n","            'name_to_id': name_to_id,\n","            'num_categories': len(categories)\n","        },\n","        'pill_code_mapping': {\n","            'code_to_id': new_code_to_id,\n","            'id_to_code': new_id_to_code,\n","            'sorted_codes': sorted_pill_codes,\n","            'total_classes': len(sorted_pill_codes)\n","        }\n","    }\n","\n","    print(f\"âœ… COCO ì›ë³¸ ì¹´í…Œê³ ë¦¬: {len(categories)}ê°œ\")\n","    print(f\"âœ… íŒŒì¼ëª… ê¸°ë°˜ ì•Œì•½ ì½”ë“œ: {len(sorted_pill_codes)}ê°œ\")\n","\n","    return mapping_info\n","\n","def convert_bbox_format(bbox, from_format, to_format, image_width=None, image_height=None):\n","    \"\"\"\n","    ë°”ìš´ë”© ë°•ìŠ¤ í¬ë§· ë³€í™˜\n","\n","    Args:\n","        bbox: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n","        from_format: ì…ë ¥ í¬ë§· ('coco', 'yolo', 'pascal')\n","        to_format: ì¶œë ¥ í¬ë§· ('coco', 'yolo', 'pascal', 'relative')\n","        image_width: ì´ë¯¸ì§€ ë„ˆë¹„\n","        image_height: ì´ë¯¸ì§€ ë†’ì´\n","\n","    Returns:\n","        list: ë³€í™˜ëœ ë°”ìš´ë”© ë°•ìŠ¤\n","    \"\"\"\n","    # COCO í¬ë§·ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”\n","    if from_format == 'coco':\n","        # COCO: [x, y, width, height] (ì¢Œìƒë‹¨ ê¸°ì¤€)\n","        x, y, w, h = bbox\n","    elif from_format == 'pascal' or from_format == 'pascal_voc':\n","        # Pascal VOC: [x_min, y_min, x_max, y_max]\n","        x_min, y_min, x_max, y_max = bbox\n","        x, y = x_min, y_min\n","        w, h = x_max - x_min, y_max - y_min\n","    elif from_format == 'yolo':\n","        # YOLO: [center_x_rel, center_y_rel, width_rel, height_rel] (ìƒëŒ€ ì¢Œí‘œ)\n","        if image_width is None or image_height is None:\n","            raise ValueError(\"YOLO í¬ë§· ë³€í™˜ì—ëŠ” ì´ë¯¸ì§€ í¬ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n","        cx_rel, cy_rel, w_rel, h_rel = bbox\n","        w = w_rel * image_width\n","        h = h_rel * image_height\n","        x = (cx_rel * image_width) - w/2\n","        y = (cy_rel * image_height) - h/2\n","    else:\n","        raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ í¬ë§·: {from_format}\")\n","\n","    # ëª©í‘œ í¬ë§·ìœ¼ë¡œ ë³€í™˜\n","    if to_format == 'coco':\n","        return [x, y, w, h]\n","    elif to_format == 'pascal':\n","        return [x, y, x + w, y + h]\n","    elif to_format == 'yolo':\n","        if image_width is None or image_height is None:\n","            raise ValueError(\"YOLO í¬ë§· ë³€í™˜ì—ëŠ” ì´ë¯¸ì§€ í¬ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n","        center_x = (x + w/2) / image_width\n","        center_y = (y + h/2) / image_height\n","        w_rel = w / image_width\n","        h_rel = h / image_height\n","        return [center_x, center_y, w_rel, h_rel]\n","    elif to_format == 'relative':\n","        if image_width is None or image_height is None:\n","            raise ValueError(\"ìƒëŒ€ ì¢Œí‘œ ë³€í™˜ì—ëŠ” ì´ë¯¸ì§€ í¬ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n","        return [x/image_width, y/image_height, w/image_width, h/image_height]\n","    else:\n","        raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ í¬ë§·: {to_format}\")\n","\n","def process_coco_annotations(coco_data, category_mapping):\n","    \"\"\"\n","    COCO ì–´ë…¸í…Œì´ì…˜ ë°ì´í„° ì²˜ë¦¬\n","\n","    Args:\n","        coco_data: COCO í¬ë§· ë°ì´í„°\n","        category_mapping: ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ë³´\n","\n","    Returns:\n","        list: ì²˜ë¦¬ëœ ì–´ë…¸í…Œì´ì…˜ ë¦¬ìŠ¤íŠ¸\n","    \"\"\"\n","    print(\"ğŸ”„ COCO ì–´ë…¸í…Œì´ì…˜ ì²˜ë¦¬ ì¤‘...\")\n","\n","    # ì´ë¯¸ì§€ ì •ë³´ë¥¼ IDë¡œ ì¸ë±ì‹±\n","    images_by_id = {img['id']: img for img in coco_data['images']}\n","\n","    # ì´ë¯¸ì§€ë³„ë¡œ ì–´ë…¸í…Œì´ì…˜ ê·¸ë£¹í™”\n","    annotations_by_image = defaultdict(list)\n","    for ann in coco_data['annotations']:\n","        annotations_by_image[ann['image_id']].append(ann)\n","\n","    processed_data = []\n","\n","    for image_id, image_info in images_by_id.items():\n","        filename = image_info['file_name']\n","        image_width = image_info['width']\n","        image_height = image_info['height']\n","\n","        # íŒŒì¼ëª…ì—ì„œ ì•Œì•½ ì½”ë“œ ì¶”ì¶œ\n","        parsed_code = parse_pill_code(filename)\n","\n","        # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ëª¨ë“  ì–´ë…¸í…Œì´ì…˜ ì²˜ë¦¬\n","        objects = []\n","        for ann in annotations_by_image[image_id]:\n","            # ì›ë³¸ COCO bbox\n","            coco_bbox = ann['bbox']  # [x, y, width, height]\n","\n","            # ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ë³€í™˜\n","            bbox_formats = {\n","                'coco': coco_bbox,\n","                'pascal_voc': convert_bbox_format(coco_bbox, 'coco', 'pascal'),\n","                'yolo': convert_bbox_format(coco_bbox, 'coco', 'yolo', image_width, image_height),\n","                'relative': convert_bbox_format(coco_bbox, 'coco', 'relative', image_width, image_height)\n","            }\n","\n","            # í´ë˜ìŠ¤ ì •ë³´\n","            original_category_id = ann['category_id']\n","            new_class_id = category_mapping['pill_code_mapping']['code_to_id'].get(\n","                parsed_code['full_code'], -1\n","            )\n","\n","            class_info = {\n","                'original_category_id': original_category_id,\n","                'new_class_id': new_class_id,\n","                'pill_code': parsed_code['full_code'],\n","                'hierarchical': {\n","                    'prefix': parsed_code['prefix'],\n","                    'code1': parsed_code['code1'],\n","                    'code2': parsed_code['code2'],\n","                    'code3': parsed_code['code3']\n","                }\n","            }\n","\n","            # ê°ì²´ ì •ë³´\n","            obj_info = {\n","                'annotation_id': ann['id'],\n","                'bbox_formats': bbox_formats,\n","                'class_info': class_info,\n","                'area': ann.get('area', coco_bbox[2] * coco_bbox[3]),\n","                'area_relative': bbox_formats['relative'][2] * bbox_formats['relative'][3],\n","                'iscrowd': ann.get('iscrowd', 0)\n","            }\n","\n","            objects.append(obj_info)\n","\n","        # ì´ë¯¸ì§€ë³„ ì •ë³´\n","        image_data = {\n","            'image_id': image_id,\n","            'filename': filename,\n","            'image_size': (image_width, image_height),\n","            'pill_code': parsed_code['full_code'],\n","            'parsed_code': parsed_code,\n","            'objects': objects,\n","            'num_objects': len(objects)\n","        }\n","\n","        processed_data.append(image_data)\n","\n","    print(f\"âœ… {len(processed_data)}ê°œ ì´ë¯¸ì§€ì˜ ì–´ë…¸í…Œì´ì…˜ ì²˜ë¦¬ ì™„ë£Œ\")\n","    return processed_data\n","\n","def export_to_yolo_format(processed_data, output_dir, category_mapping):\n","    \"\"\"\n","    YOLO í¬ë§·ìœ¼ë¡œ ì–´ë…¸í…Œì´ì…˜ ë‚´ë³´ë‚´ê¸°\n","\n","    Args:\n","        processed_data: ì²˜ë¦¬ëœ ì–´ë…¸í…Œì´ì…˜ ë°ì´í„°\n","        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬\n","        category_mapping: ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ë³´\n","    \"\"\"\n","    print(\"ğŸ“ YOLO í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°...\")\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for image_data in processed_data:\n","        if image_data['objects']:\n","            # íŒŒì¼ëª… ìƒì„± (.txt)\n","            base_name = image_data['filename'].replace('.png', '').replace('.jpg', '')\n","            output_file = os.path.join(output_dir, f\"{base_name}.txt\")\n","\n","            with open(output_file, 'w') as f:\n","                for obj in image_data['objects']:\n","                    class_id = obj['class_info']['new_class_id']\n","                    if class_id >= 0:  # ìœ íš¨í•œ í´ë˜ìŠ¤ IDë§Œ\n","                        yolo_bbox = obj['bbox_formats']['yolo']\n","\n","                        # YOLO í¬ë§·: class_id center_x center_y width height\n","                        line = f\"{class_id} {yolo_bbox[0]:.6f} {yolo_bbox[1]:.6f} {yolo_bbox[2]:.6f} {yolo_bbox[3]:.6f}\\n\"\n","                        f.write(line)\n","\n","    # í´ë˜ìŠ¤ ì´ë¦„ íŒŒì¼ ìƒì„±\n","    classes_file = os.path.join(output_dir, 'classes.txt')\n","    with open(classes_file, 'w', encoding='utf-8') as f:\n","        pill_mapping = category_mapping['pill_code_mapping']\n","        for class_id in range(pill_mapping['total_classes']):\n","            class_name = pill_mapping['id_to_code'][str(class_id)]\n","            f.write(f\"{class_name}\\n\")\n","\n","    print(f\"âœ… YOLO í¬ë§· íŒŒì¼ë“¤ì´ {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤\")\n","    print(f\"âœ… í´ë˜ìŠ¤ íŒŒì¼: {classes_file}\")\n","\n","def export_to_pascal_voc_format(processed_data, output_dir):\n","    \"\"\"\n","    Pascal VOC XML í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (ê°„ë‹¨ ë²„ì „)\n","    \"\"\"\n","    print(\"ğŸ“ Pascal VOC í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°...\")\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # CSV í˜•íƒœë¡œ ì €ì¥ (XML ëŒ€ì‹  ê°„ë‹¨í•œ í˜•íƒœ)\n","    annotations_list = []\n","\n","    for image_data in processed_data:\n","        for obj in image_data['objects']:\n","            if obj['class_info']['new_class_id'] >= 0:\n","                pascal_bbox = obj['bbox_formats']['pascal_voc']\n","\n","                annotations_list.append({\n","                    'filename': image_data['filename'],\n","                    'width': image_data['image_size'][0],\n","                    'height': image_data['image_size'][1],\n","                    'class': obj['class_info']['pill_code'],\n","                    'xmin': int(pascal_bbox[0]),\n","                    'ymin': int(pascal_bbox[1]),\n","                    'xmax': int(pascal_bbox[2]),\n","                    'ymax': int(pascal_bbox[3])\n","                })\n","\n","    # CSVë¡œ ì €ì¥\n","    df = pd.DataFrame(annotations_list)\n","    csv_file = os.path.join(output_dir, 'annotations_pascal_voc.csv')\n","    df.to_csv(csv_file, index=False)\n","\n","    print(f\"âœ… Pascal VOC í¬ë§· (CSV)ì´ {csv_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤\")\n","\n","def create_annotation_statistics(processed_data, category_mapping):\n","    \"\"\"\n","    ì–´ë…¸í…Œì´ì…˜ í†µê³„ ìƒì„±\n","\n","    Args:\n","        processed_data: ì²˜ë¦¬ëœ ì–´ë…¸í…Œì´ì…˜ ë°ì´í„°\n","        category_mapping: ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ë³´\n","\n","    Returns:\n","        dict: í†µê³„ ì •ë³´\n","    \"\"\"\n","    print(\"ğŸ“Š ì–´ë…¸í…Œì´ì…˜ í†µê³„ ìƒì„± ì¤‘...\")\n","\n","    class_counts = Counter()\n","    class_areas = defaultdict(list)\n","    class_bbox_sizes = defaultdict(list)\n","    total_objects = 0\n","\n","    for image_data in processed_data:\n","        for obj in image_data['objects']:\n","            pill_code = obj['class_info']['pill_code']\n","            class_counts[pill_code] += 1\n","            total_objects += 1\n","\n","            class_areas[pill_code].append(obj['area_relative'])\n","\n","            # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° (ìƒëŒ€ ì¢Œí‘œ)\n","            rel_bbox = obj['bbox_formats']['relative']\n","            class_bbox_sizes[pill_code].append((rel_bbox[2], rel_bbox[3]))\n","\n","    # ì´ë¯¸ì§€ë‹¹ ê°ì²´ ìˆ˜ í†µê³„\n","    objects_per_image = [len(img['objects']) for img in processed_data]\n","\n","    # í†µê³„ ê³„ì‚°\n","    stats = {\n","        'summary': {\n","            'total_images': len(processed_data),\n","            'total_objects': total_objects,\n","            'avg_objects_per_image': total_objects / len(processed_data) if processed_data else 0,\n","            'min_objects_per_image': min(objects_per_image) if objects_per_image else 0,\n","            'max_objects_per_image': max(objects_per_image) if objects_per_image else 0\n","        },\n","        'class_distribution': dict(class_counts.most_common()),\n","        'num_classes': len(class_counts),\n","        'class_details': {}\n","    }\n","\n","    for pill_code, count in class_counts.items():\n","        areas = class_areas[pill_code]\n","        sizes = class_bbox_sizes[pill_code]\n","\n","        stats['class_details'][pill_code] = {\n","            'count': count,\n","            'percentage': (count / total_objects) * 100 if total_objects > 0 else 0,\n","            'avg_area': sum(areas) / len(areas) if areas else 0,\n","            'avg_width': sum(size[0] for size in sizes) / len(sizes) if sizes else 0,\n","            'avg_height': sum(size[1] for size in sizes) / len(sizes) if sizes else 0,\n","            'min_area': min(areas) if areas else 0,\n","            'max_area': max(areas) if areas else 0\n","        }\n","\n","    return stats\n","\n","def preprocess_coco_annotations(data_path, output_dir):\n","    \"\"\"\n","    COCO í¬ë§· ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜\n","\n","    Args:\n","        data_path: ì…ë ¥ ë°ì´í„°ì…‹ ê²½ë¡œ (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê³³)\n","        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬\n","\n","    Returns:\n","        dict: ì „ì²˜ë¦¬ ê²°ê³¼\n","    \"\"\"\n","    print(\"ğŸš€ COCO ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬ ì‹œì‘!\")\n","    print(f\"ğŸ“ ì…ë ¥: {data_path}\")\n","    print(f\"ğŸ“ ì¶œë ¥: {output_dir}\")\n","    print(\"=\" * 50)\n","\n","    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n","    os.makedirs(output_dir, exist_ok=True)\n","    yolo_dir = os.path.join(output_dir, \"yolo_format\")\n","    pascal_dir = os.path.join(output_dir, \"pascal_voc_format\")\n","\n","    # 1. COCO ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ë“¤ ì°¾ê¸°\n","    annotation_files = glob.glob(os.path.join(data_path, \"train_annotations\", \"*\", \"*\", \"*.json\"))\n","\n","    if not annotation_files:\n","        print(\"âŒ COCO ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n","        return None\n","\n","    print(f\"ğŸ“‹ ë°œê²¬ëœ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼: {len(annotation_files)}ê°œ\")\n","\n","    # 2. ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ìƒì„± (ëª¨ë“  íŒŒì¼ì´ ê°™ì€ êµ¬ì¡°ë¼ê³  ê°€ì •)\n","    first_ann_result = read_coco_annotation(annotation_files[0])\n","    if first_ann_result['status'] != 'success':\n","        print(f\"âŒ ì²« ë²ˆì§¸ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {first_ann_result['error']}\")\n","        return None\n","\n","    category_mapping = create_category_mapping_from_coco(first_ann_result['data'])\n","\n","    # 3. ëª¨ë“  ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì²˜ë¦¬\n","    all_processed_data = []\n","    failed_files = []\n","\n","    print(f\"\\nğŸ”„ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì²˜ë¦¬ ì¤‘...\")\n","\n","    for i, ann_path in enumerate(annotation_files):\n","        ann_result = read_coco_annotation(ann_path)\n","\n","        if ann_result['status'] == 'success':\n","            processed_data = process_coco_annotations(ann_result['data'], category_mapping)\n","            all_processed_data.extend(processed_data)\n","        else:\n","            failed_files.append({\n","                'path': ann_path,\n","                'error': ann_result['error']\n","            })\n","\n","        # ì§„í–‰ë¥  ì¶œë ¥\n","        if (i + 1) % 10 == 0:\n","            print(f\"  ì§„í–‰ë¥ : {i + 1}/{len(annotation_files)}\")\n","\n","    # 4. í†µê³„ ìƒì„±\n","    stats = create_annotation_statistics(all_processed_data, category_mapping)\n","\n","    # 5. ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\n","    print(f\"\\nğŸ“¤ ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°...\")\n","\n","    # YOLO í¬ë§·\n","    export_to_yolo_format(all_processed_data, yolo_dir, category_mapping)\n","\n","    # Pascal VOC í¬ë§·\n","    export_to_pascal_voc_format(all_processed_data, pascal_dir)\n","\n","    # ê²°ê³¼ ì €ì¥\n","    # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì €ì¥\n","    mapping_file = os.path.join(output_dir, \"category_mapping.json\")\n","    with open(mapping_file, 'w', encoding='utf-8') as f:\n","        json.dump(category_mapping, f, indent=2, ensure_ascii=False)\n","\n","    # í†µê³„ ì €ì¥\n","    stats_file = os.path.join(output_dir, \"annotation_statistics.json\")\n","    with open(stats_file, 'w', encoding='utf-8') as f:\n","        json.dump(stats, f, indent=2, ensure_ascii=False)\n","\n","    # 6. ê²°ê³¼ ìš”ì•½\n","    print(f\"\\nğŸ“Š COCO ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬ ê²°ê³¼:\")\n","    print(f\"  âœ… ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(all_processed_data)}ê°œ\")\n","    print(f\"  âœ… ì´ ê°ì²´ ìˆ˜: {stats['summary']['total_objects']}ê°œ\")\n","    print(f\"  âœ… í´ë˜ìŠ¤ ìˆ˜: {stats['num_classes']}ê°œ\")\n","    print(f\"  ğŸ“ˆ í‰ê·  ê°ì²´/ì´ë¯¸ì§€: {stats['summary']['avg_objects_per_image']:.1f}ê°œ\")\n","    print(f\"  âŒ ì‹¤íŒ¨í•œ íŒŒì¼: {len(failed_files)}ê°œ\")\n","\n","    # ìƒìœ„ í´ë˜ìŠ¤ ì¶œë ¥\n","    print(f\"\\nğŸ” ìƒìœ„ 5ê°œ í´ë˜ìŠ¤:\")\n","    for pill_code, count in list(stats['class_distribution'].items())[:5]:\n","        percentage = stats['class_details'][pill_code]['percentage']\n","        print(f\"  {pill_code}: {count}ê°œ ({percentage:.1f}%)\")\n","\n","    if failed_files:\n","        print(f\"\\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\")\n","        for fail in failed_files[:3]:\n","            print(f\"  - {fail['path']}: {fail['error']}\")\n","        if len(failed_files) > 3:\n","            print(f\"  ... ì™¸ {len(failed_files) - 3}ê°œ\")\n","\n","    return {\n","        'processed_data': all_processed_data,\n","        'failed_files': failed_files,\n","        'category_mapping': category_mapping,\n","        'statistics': stats,\n","        'output_files': {\n","            'yolo_dir': yolo_dir,\n","            'pascal_dir': pascal_dir,\n","            'mapping_file': mapping_file,\n","            'stats_file': stats_file\n","        }\n","    }\n","\n","def debug_coco_files(data_path):\n","    \"\"\"COCO íŒŒì¼ ë””ë²„ê¹… í•¨ìˆ˜\"\"\"\n","    print(\"ğŸ” COCO íŒŒì¼ ë””ë²„ê¹…...\")\n","\n","    # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸\n","    annotation_files = glob.glob(os.path.join(data_path, \"train_annotations\", \"*\", \"*\", \"*.json\"))\n","    print(f\"1ï¸âƒ£ ë°œê²¬ëœ JSON íŒŒì¼: {len(annotation_files)}ê°œ\")\n","\n","    if not annotation_files:\n","        print(\"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n","        return None\n","\n","    # 2. ì²« ë²ˆì§¸ íŒŒì¼ ì½ê¸°\n","    first_file = annotation_files[0]\n","    print(f\"2ï¸âƒ£ ì²« ë²ˆì§¸ íŒŒì¼: {first_file}\")\n","\n","    try:\n","        with open(first_file, 'r', encoding='utf-8') as f:\n","            coco_data = json.load(f)\n","\n","        print(f\"3ï¸âƒ£ COCO êµ¬ì¡°:\")\n","        print(f\"   - í‚¤: {list(coco_data.keys())}\")\n","        print(f\"   - ì´ë¯¸ì§€ ìˆ˜: {len(coco_data.get('images', []))}\")\n","        print(f\"   - ì–´ë…¸í…Œì´ì…˜ ìˆ˜: {len(coco_data.get('annotations', []))}\")\n","        print(f\"   - ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(coco_data.get('categories', []))}\")\n","\n","        # 3. ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥\n","        if coco_data.get('images'):\n","            print(f\"4ï¸âƒ£ ìƒ˜í”Œ ì´ë¯¸ì§€ ì •ë³´:\")\n","            for i, img in enumerate(coco_data['images'][:3]):\n","                print(f\"   {i+1}. {img.get('file_name', 'NO_FILENAME')}\")\n","                parsed = parse_pill_code(img.get('file_name', ''))\n","                print(f\"      â†’ íŒŒì‹±: {parsed['full_code']} (ìœ íš¨: {parsed['is_valid']})\")\n","\n","        return coco_data\n","\n","    except Exception as e:\n","        print(f\"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\")\n","        return None\n","\n","def quick_preprocess_prototype_annotations():\n","    \"\"\"í”„ë¡œí† íƒ€ì… ë°ì´í„° COCO ì–´ë…¸í…Œì´ì…˜ ë¹ ë¥¸ ì „ì²˜ë¦¬ (ë””ë²„ê¹… í¬í•¨)\"\"\"\n","\n","    # 1. ë¨¼ì € ë””ë²„ê¹…\n","    print(\"ğŸ” ì‚¬ì „ ë””ë²„ê¹…...\")\n","    debug_result = debug_coco_files(\"./data/preprocessed_prototype_data\")\n","\n","    if debug_result is None:\n","        print(\"âŒ ë””ë²„ê¹… ì‹¤íŒ¨. ì „ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n","        return None\n","\n","    # 2. ì‹¤ì œ ì „ì²˜ë¦¬ ì‹¤í–‰\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"ğŸš€ ì‹¤ì œ ì „ì²˜ë¦¬ ì‹œì‘...\")\n","    return preprocess_coco_annotations(\n","        \"./data/prototype_data/preprocessed_prototype_data\",\n","        \"./data/annotations_prototype\"\n","    )\n","\n","def quick_preprocess_dev_annotations():\n","    \"\"\"ê°œë°œìš© ë°ì´í„° COCO ì–´ë…¸í…Œì´ì…˜ ë¹ ë¥¸ ì „ì²˜ë¦¬\"\"\"\n","    return preprocess_coco_annotations(\n","        \"./data/preprocessed_dev_data\",\n","        \"./data/annotations_dev\"\n","    )\n","\n","# ì‚¬ìš©ë²• ì˜ˆì‹œ\n","if __name__ == \"__main__\":\n","    print(\"ğŸ“– ì‚¬ìš©ë²• (COCO í¬ë§· ì…ë ¥):\")\n","    print(\"quick_preprocess_prototype_annotations()  # í”„ë¡œí† íƒ€ì… COCO ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬\")\n","    print(\"quick_preprocess_dev_annotations()        # ê°œë°œìš© COCO ì–´ë…¸í…Œì´ì…˜ ì „ì²˜ë¦¬\")\n","    print(\"preprocess_coco_annotations(input_path, output_path)  # ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬\")\n","\n","    prototype_coco_results = quick_preprocess_prototype_annotations()"]},{"cell_type":"code","source":[],"metadata":{"id":"R2aWtLCByF-g"},"execution_count":null,"outputs":[]}]}