{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObMsH9gYuxG5mBTp/Yyq94"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYwhmWq9zkDD","executionInfo":{"status":"ok","timestamp":1757477500869,"user_tz":-540,"elapsed":19932,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"fc6d770d-90e5-4934-88dc-9b45bb399f83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# ê¹ƒí—ˆë¸Œ ê°œë°œí™˜ê²½ ì„¸íŒ…"],"metadata":{"id":"FI3tsvnUz6Az"}},{"cell_type":"code","source":["# 1. ê¸°ì¡´ ë¦¬í¬ì§€í† ë¦¬ í´ë”ë¡œ ì´ë™\n","import os\n","os.chdir('/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project')"],"metadata":{"id":"5mvhCYUkzs7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. ê²½ë¡œ í™•ì¸\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Slm_A9XS0AtK","executionInfo":{"status":"ok","timestamp":1757477501541,"user_tz":-540,"elapsed":246,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"f6e4bdee-6589-4d40-e87b-cb57b6e391c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project\n"]}]},{"cell_type":"code","source":["# 3. ìµœì‹  ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°\n","!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"es4bKMyn0CXK","executionInfo":{"status":"ok","timestamp":1757477524562,"user_tz":-540,"elapsed":23018,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"09cba2a1-2655-44b5-82e1-e02910834167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/Dongjin-1203/Codeit_AI_4th_Drug_image_CV_project\n"," * branch            main       -> FETCH_HEAD\n","Updating a10a90e..e0c35de\n","Updating files: 100% (3/3), done.\n","Fast-forward\n"," .gitignore            | 149 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n"," README.md             |  47 \u001b[32m+++++++++++++++\u001b[m\u001b[31m-\u001b[m\n"," data/data_explane.txt |   2 \u001b[32m+\u001b[m\n"," 3 files changed, 197 insertions(+), 1 deletion(-)\n"," create mode 100644 .gitignore\n"," create mode 100644 data/data_explane.txt\n"]}]},{"cell_type":"code","source":["# 3. í˜„ì¬ ìƒíƒœ í™•ì¸\n","!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HP3xc_ic0Lf6","executionInfo":{"status":"ok","timestamp":1757477678381,"user_tz":-540,"elapsed":210,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"db91a096-4ac6-41bf-e09c-87178e6efdab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   git_clone.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mnotebooks/\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"markdown","source":["# ì½”ë“œì‡ ìŠ¤í”„ë¦°íŠ¸ ì´ˆê¸‰ íŒ€ í”„ë¡œì íŠ¸: ê²½êµ¬ì•½ì œ ì´ë¯¸ì§€ ê°ì²´ ê²€ì¶œ(Object Detection) í”„ë¡œì íŠ¸\n","\n","ì´ íŒŒì¼ì—ì„œëŠ” ì¶”í›„ ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ ê°œë°œê¹Œì§€ ì¼ë ¨ì˜ ê³¼ì •ì— í•µì‹¬ì´ ë  íƒìƒ‰ì  ë°ì´í„° íƒìƒ‰(EDA)ë¥¼ ì§„í–‰í•  ì˜ˆì •ì´ë‹¤.\n","\n","## ë°ì´í„° íƒìƒ‰ ìš”ì†Œ\n","1. í´ë” êµ¬ì¡° ë° íŒŒì¼ ê°œìˆ˜ í™•ì¸\n","2. JSON annotation ìŠ¤í‚¤ë§ˆ ë¶„ì„      \n","3. ì´ë¯¸ì§€ ë°ì´í„° ë¶„ì„\n","    - ì´ë¯¸ì§€ í•´ìƒë„, í¬ê¸° ë¶„í¬\n","    - ì´ë¯¸ì§€ í’ˆì§ˆ ê²€ì‚¬(ì†ìƒëœ íŒŒì¼, ë…¸ì´ì¦ˆ ë“±)\n","    - ìƒ‰ìƒ ë¶„í¬ ë° ë°ê¸° ë¶„ì„\n","    - ì•Œì•½ í˜•íƒœë³„ ë¶„í¬\n","4. ë¼ë²¨ ë°ì´í„° ë¶„ì„\n","    - í´ë˜ìŠ¤ ë¶„í¬ ë° ë¶ˆê· í˜• í™•ì¸\n","    - ì•Œì•½ ì¢…ë¥˜ë³„ í†µê³„\n","    - ì œì•½íšŒì‚¬ë³„, ì„±ë¶„ë³„ ë¶„í¬(íŒë‹¨ í•„ìš”)\n","    - Missing value ë° ì´ìƒì¹˜ íƒì§€\n","\n","í•œë²ˆì— ì‹¤í–‰í•˜ì§€ ì•Šê³  ë‹¨ê³„ë³„ë¡œ ì§„í–‰í•  ì˜ˆì •"],"metadata":{"id":"4OKS3YPx2Gu3"}},{"cell_type":"markdown","source":["## 1. ì´ˆê¸° ì„¸íŒ…"],"metadata":{"id":"s8KIZxJf5s-i"}},{"cell_type":"code","source":["# í•œê¸€ í°íŠ¸ ì„¤ì •\n","!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf\n","\n","print(\"í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì™„ë£Œ!\")"],"metadata":{"id":"I7ux6Yj93Bmr","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757478852092,"user_tz":-540,"elapsed":9693,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"1763b6de-8f49-4f26-aa6c-32714d70663c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n","Need to get 10.3 MB of archives.\n","After this operation, 34.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n","Fetched 10.3 MB in 0s (43.6 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 126374 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n","Unpacking fonts-nanum (20200506-1) ...\n","Setting up fonts-nanum (20200506-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/usr/share/fonts/truetype: skipping, looped directory detected\n","/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n","/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n","/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n","í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì™„ë£Œ!\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from PIL import Image\n","import numpy as np\n","from collections import Counter, defaultdict\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"gz3xtVJ15u7r","executionInfo":{"status":"ok","timestamp":1757481206753,"user_tz":-540,"elapsed":3,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# í•œê¸€ í°íŠ¸ ì„¤ì •\n","plt.rcParams['font.family'] = 'DejaVu Sans'\n","plt.rcParams['axes.unicode_minus'] = False"],"metadata":{"id":"ny8_PbOg513U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. í´ë” êµ¬ì¡° ë° íŒŒì¼ ê°œìˆ˜ ë¶„ì„"],"metadata":{"id":"ZRpuQNhx5-pK"}},{"cell_type":"markdown","source":["### í´ë” êµ¬ì¡° ë° íŒŒì¼ ê°œìˆ˜ í™•ì¸"],"metadata":{"id":"HUjCDjQl8Y09"}},{"cell_type":"code","source":["def check_dataset_structure(data_path):\n","    \"\"\"ë°ì´í„°ì…‹ ê¸°ë³¸ êµ¬ì¡° í™•ì¸\"\"\"\n","    data_path = Path(data_path)\n","\n","    print(\"=\"*60)\n","    print(\"ğŸ“ ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„\")\n","    print(\"=\"*60)\n","\n","    if not data_path.exists():\n","        print(f\"âŒ ê²½ë¡œ ì—†ìŒ: {data_path}\")\n","        return {}\n","\n","    results = {}\n","\n","    # Train ì´ë¯¸ì§€ í™•ì¸\n","    train_img_path = data_path / \"train_images\"\n","    if train_img_path.exists():\n","        train_images = list(train_img_path.glob(\"*.png\"))\n","        results['train_images'] = len(train_images)\n","        print(f\"âœ… Train ì´ë¯¸ì§€: {len(train_images):,}ê°œ\")\n","\n","        # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„\n","        if train_images:\n","            sample_names = [f.stem for f in train_images[:5]]\n","            print(f\"ğŸ“ Train íŒŒì¼ëª… ìƒ˜í”Œ:\")\n","            for name in sample_names:\n","                print(f\"   {name}\")\n","    else:\n","        results['train_images'] = 0\n","        print(\"âŒ train_images í´ë” ì—†ìŒ\")\n","\n","    # Test ì´ë¯¸ì§€ í™•ì¸\n","    test_img_path = data_path / \"test_images\"\n","    if test_img_path.exists():\n","        test_images = list(test_img_path.glob(\"*.png\"))\n","        results['test_images'] = len(test_images)\n","        print(f\"âœ… Test ì´ë¯¸ì§€: {len(test_images):,}ê°œ\")\n","    else:\n","        results['test_images'] = 0\n","        print(\"âŒ test_images í´ë” ì—†ìŒ\")\n","\n","    # Annotation í´ë” êµ¬ì¡° í™•ì¸\n","    train_ann_path = data_path / \"train_annotations\"\n","    if train_ann_path.exists():\n","        print(f\"âœ… Train annotations í´ë” ì¡´ì¬\")\n","\n","        # í•˜ìœ„ í´ë” êµ¬ì¡° íƒìƒ‰\n","        all_json_files = list(train_ann_path.glob(\"**/*.json\"))\n","        results['train_annotations'] = len(all_json_files)\n","        print(f\"ğŸ“ ì´ JSON íŒŒì¼: {len(all_json_files):,}ê°œ\")\n","\n","        # í´ë” êµ¬ì¡° ë¶„ì„\n","        subfolders = [d for d in train_ann_path.iterdir() if d.is_dir()]\n","        print(f\"ğŸ“‚ Annotation í•˜ìœ„ í´ë”: {len(subfolders)}ê°œ\")\n","\n","        for subfolder in subfolders[:3]:  # ì²˜ìŒ 3ê°œë§Œ\n","            sub_subfolders = [d for d in subfolder.iterdir() if d.is_dir()]\n","            json_count = len(list(subfolder.glob(\"**/*.json\")))\n","            print(f\"   ğŸ“ {subfolder.name}/ ({len(sub_subfolders)}ê°œ í•˜ìœ„í´ë”, {json_count}ê°œ JSON)\")\n","\n","        if len(subfolders) > 3:\n","            print(f\"   ... ì™¸ {len(subfolders)-3}ê°œ í´ë”\")\n","\n","    else:\n","        results['train_annotations'] = 0\n","        print(\"âŒ train_annotations í´ë” ì—†ìŒ\")\n","\n","    return results"],"metadata":{"id":"RIPSmsfI52t7","executionInfo":{"status":"ok","timestamp":1757481234218,"user_tz":-540,"elapsed":16,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["### Annotation ê¸°ë³¸ ì •ë³´ í™•ì¸"],"metadata":{"id":"qeKjTlZk8bwY"}},{"cell_type":"code","source":["def check_annotation_sample(data_path, sample_count=3):\n","    \"\"\"ìƒ˜í”Œ annotation JSON íŒŒì¼ êµ¬ì¡° í™•ì¸\"\"\"\n","    train_ann_path = Path(data_path) / \"train_annotations\"\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"ğŸ“ Annotation JSON ìƒ˜í”Œ ë¶„ì„ ({sample_count}ê°œ)\")\n","    print(\"=\"*60)\n","\n","    if not train_ann_path.exists():\n","        print(\"âŒ train_annotations í´ë” ì—†ìŒ\")\n","        return None\n","\n","    # JSON íŒŒì¼ë“¤ ì°¾ê¸°\n","    json_files = list(train_ann_path.glob(\"**/*.json\"))[:sample_count]\n","\n","    if not json_files:\n","        print(\"âŒ JSON íŒŒì¼ ì—†ìŒ\")\n","        return None\n","\n","    sample_data = []\n","\n","    for i, json_file in enumerate(json_files, 1):\n","        print(f\"\\nğŸ” ìƒ˜í”Œ {i}: {json_file.name}\")\n","        print(f\"   ê²½ë¡œ: {json_file.relative_to(train_ann_path)}\")\n","\n","        try:\n","            with open(json_file, 'r', encoding='utf-8') as f:\n","                data = json.load(f)\n","\n","            print(f\"   ğŸ“Š JSON êµ¬ì¡°:\")\n","            print(f\"      íƒ€ì…: {type(data)}\")\n","\n","            if isinstance(data, dict):\n","                print(f\"      í‚¤ë“¤: {list(data.keys())}\")\n","\n","                # ê° í‚¤ì˜ ë‚´ìš© ê°„ë‹¨íˆ í™•ì¸\n","                for key, value in data.items():\n","                    if isinstance(value, list):\n","                        print(f\"         {key}: ë¦¬ìŠ¤íŠ¸ ({len(value)}ê°œ)\")\n","                        if value and isinstance(value[0], dict):\n","                            print(f\"            ì²« ìš”ì†Œ í‚¤: {list(value[0].keys())}\")\n","                    elif isinstance(value, dict):\n","                        print(f\"         {key}: ë”•ì…”ë„ˆë¦¬ ({len(value)}ê°œ í‚¤)\")\n","                        print(f\"            í‚¤ë“¤: {list(value.keys())}\")\n","                    else:\n","                        print(f\"         {key}: {type(value).__name__} = {value}\")\n","\n","            elif isinstance(data, list):\n","                print(f\"      ë¦¬ìŠ¤íŠ¸ ê¸¸ì´: {len(data)}\")\n","                if data and isinstance(data[0], dict):\n","                    print(f\"      ì²« ìš”ì†Œ í‚¤: {list(data[0].keys())}\")\n","\n","            sample_data.append(data)\n","\n","        except Exception as e:\n","            print(f\"   âŒ JSON ì½ê¸° ì˜¤ë¥˜: {e}\")\n","\n","    return sample_data"],"metadata":{"id":"40LU1UV26lgx","executionInfo":{"status":"ok","timestamp":1757481250125,"user_tz":-540,"elapsed":1,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["### ì´ë¯¸ì§€ì™€ annotation íŒŒì¼ ë§¤ì¹­ í™•ì¸"],"metadata":{"id":"elF2c9gm8gsR"}},{"cell_type":"code","source":["def check_file_matching(data_path):\n","    \"\"\"ì´ë¯¸ì§€ì™€ annotation íŒŒì¼ ë§¤ì¹­ í™•ì¸\"\"\"\n","    data_path = Path(data_path)\n","    train_img_path = data_path / \"train_images\"\n","    train_ann_path = data_path / \"train_annotations\"\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ğŸ”— ì´ë¯¸ì§€-Annotation ë§¤ì¹­ í™•ì¸\")\n","    print(\"=\"*60)\n","\n","    if not train_img_path.exists() or not train_ann_path.exists():\n","        print(\"âŒ í•„ìš”í•œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤\")\n","        return\n","\n","    # ì´ë¯¸ì§€ íŒŒì¼ëª…ë“¤\n","    image_files = list(train_img_path.glob(\"*.png\"))\n","    image_names = {f.stem for f in image_files}\n","\n","    # JSON íŒŒì¼ëª…ë“¤\n","    json_files = list(train_ann_path.glob(\"**/*.json\"))\n","    json_names = {f.stem for f in json_files}\n","\n","    print(f\"ğŸ–¼ï¸  ì´ë¯¸ì§€ íŒŒì¼: {len(image_names):,}ê°œ\")\n","    print(f\"ğŸ“ JSON íŒŒì¼: {len(json_names):,}ê°œ\")\n","\n","    # ë§¤ì¹­ í™•ì¸\n","    matched = image_names.intersection(json_names)\n","    image_only = image_names - json_names\n","    json_only = json_names - image_names\n","\n","    print(f\"âœ… ë§¤ì¹­ë¨: {len(matched):,}ê°œ\")\n","    print(f\"ğŸ–¼ï¸  ì´ë¯¸ì§€ë§Œ ìˆìŒ: {len(image_only):,}ê°œ\")\n","    print(f\"ğŸ“ JSONë§Œ ìˆìŒ: {len(json_only):,}ê°œ\")\n","\n","    # ë§¤ì¹­ ì•ˆëœ íŒŒì¼ë“¤ ìƒ˜í”Œ ì¶œë ¥\n","    if image_only:\n","        print(f\"\\nğŸ“ ì´ë¯¸ì§€ë§Œ ìˆëŠ” íŒŒì¼ ìƒ˜í”Œ:\")\n","        for name in list(image_only)[:5]:\n","            print(f\"   {name}\")\n","        if len(image_only) > 5:\n","            print(f\"   ... ì™¸ {len(image_only)-5}ê°œ\")\n","\n","    if json_only:\n","        print(f\"\\nğŸ“ JSONë§Œ ìˆëŠ” íŒŒì¼ ìƒ˜í”Œ:\")\n","        for name in list(json_only)[:5]:\n","            print(f\"   {name}\")\n","        if len(json_only) > 5:\n","            print(f\"   ... ì™¸ {len(json_only)-5}ê°œ\")\n","\n","    return {\n","        'matched': len(matched),\n","        'image_only': len(image_only),\n","        'json_only': len(json_only),\n","        'match_rate': len(matched) / max(len(image_names), 1) * 100\n","    }"],"metadata":{"id":"HC5fPKvL6qNw","executionInfo":{"status":"ok","timestamp":1757481279679,"user_tz":-540,"elapsed":15,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Annotation í´ë” íŒ¨í„´ ë¶„ì„"],"metadata":{"id":"yUO8uXhA8kVH"}},{"cell_type":"code","source":["def analyze_folder_patterns(data_path):\n","    \"\"\"Annotation í´ë” íŒ¨í„´ ë¶„ì„\"\"\"\n","    train_ann_path = Path(data_path) / \"train_annotations\"\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ğŸ“‚ Annotation í´ë” íŒ¨í„´ ë¶„ì„\")\n","    print(\"=\"*60)\n","\n","    if not train_ann_path.exists():\n","        print(\"âŒ train_annotations í´ë” ì—†ìŒ\")\n","        return\n","\n","    # ì²« ë²ˆì§¸ ë ˆë²¨ í´ë”ë“¤\n","    first_level = [d for d in train_ann_path.iterdir() if d.is_dir()]\n","    print(f\"ğŸ“ 1ë‹¨ê³„ í´ë”: {len(first_level)}ê°œ\")\n","\n","    for folder in first_level[:3]:\n","        print(f\"\\nğŸ” {folder.name}/\")\n","\n","        # ë‘ ë²ˆì§¸ ë ˆë²¨ í´ë”ë“¤\n","        second_level = [d for d in folder.iterdir() if d.is_dir()]\n","        json_files = list(folder.glob(\"**/*.json\"))\n","\n","        print(f\"   ğŸ“ í•˜ìœ„ í´ë”: {len(second_level)}ê°œ\")\n","        print(f\"   ğŸ“ JSON íŒŒì¼: {len(json_files)}ê°œ\")\n","\n","        # í´ë”ëª… íŒ¨í„´ ë¶„ì„\n","        if second_level:\n","            folder_names = [d.name for d in second_level[:5]]\n","            print(f\"   ğŸ“‹ í•˜ìœ„ í´ë”ëª… ìƒ˜í”Œ: {folder_names}\")\n","\n","            # ê° í•˜ìœ„ í´ë”ì˜ JSON ê°œìˆ˜\n","            for sub_folder in second_level[:3]:\n","                sub_json = len(list(sub_folder.glob(\"*.json\")))\n","                print(f\"      {sub_folder.name}: {sub_json}ê°œ JSON\")"],"metadata":{"id":"LdbUeuev6smZ","executionInfo":{"status":"ok","timestamp":1757481298651,"user_tz":-540,"elapsed":3,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["### ì‹¤í–‰"],"metadata":{"id":"5AqW6Nv36z-N"}},{"cell_type":"code","source":["def quick_dataset_analysis(data_path):\n","    \"\"\"ì „ì²´ ë°ì´í„°ì…‹ ë¹ ë¥¸ ë¶„ì„\"\"\"\n","    print(\"ğŸš€ ê²½êµ¬ì•Œì•½ ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘\")\n","    print(f\"ğŸ“‚ ë¶„ì„ ê²½ë¡œ: {data_path}\")\n","\n","    # 1. ê¸°ë³¸ êµ¬ì¡° í™•ì¸\n","    structure_results = check_dataset_structure(data_path)\n","\n","    # 2. ìƒ˜í”Œ annotation í™•ì¸\n","    sample_data = check_annotation_sample(data_path)\n","\n","    # 3. íŒŒì¼ ë§¤ì¹­ í™•ì¸\n","    matching_results = check_file_matching(data_path)\n","\n","    # 4. í´ë” íŒ¨í„´ ë¶„ì„\n","    analyze_folder_patterns(data_path)\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ğŸ“Š ë¶„ì„ ìš”ì•½\")\n","    print(\"=\"*60)\n","    print(f\"âœ… Train ì´ë¯¸ì§€: {structure_results.get('train_images', 0):,}ê°œ\")\n","    print(f\"âœ… Test ì´ë¯¸ì§€: {structure_results.get('test_images', 0):,}ê°œ\")\n","    print(f\"âœ… Train annotations: {structure_results.get('train_annotations', 0):,}ê°œ\")\n","\n","    if matching_results:\n","        print(f\"ğŸ”— ë§¤ì¹­ë¥ : {matching_results['match_rate']:.1f}%\")\n","\n","    print(\"\\nâœ… ë¶„ì„ ì™„ë£Œ!\")\n","\n","    return structure_results, sample_data, matching_results"],"metadata":{"id":"0T4Znlqs6ujh","executionInfo":{"status":"ok","timestamp":1757481313554,"user_tz":-540,"elapsed":46,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# ì‹¤í–‰\n","if __name__ == \"__main__\":\n","    print(\"ğŸ’¡ ì‚¬ìš©ë²•:\")\n","    print(\"1. DATA_PATH ë³€ìˆ˜ë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •\")\n","    print(\"2. quick_analysis('ê²½ë¡œ') ì§ì ‘ ì‹¤í–‰\")\n","\n","    # ê²½ë¡œ ì§ì ‘ ì§€ì •í•´ì„œ ì‹¤í–‰\n","    data_path = \"data/\"\n","    results = quick_dataset_analysis(data_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKEx_Lf563md","executionInfo":{"status":"ok","timestamp":1757481350383,"user_tz":-540,"elapsed":11035,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}},"outputId":"041ec17b-8028-4aa6-adc3-75bc67160637"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ’¡ ì‚¬ìš©ë²•:\n","1. DATA_PATH ë³€ìˆ˜ë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •\n","2. quick_analysis('ê²½ë¡œ') ì§ì ‘ ì‹¤í–‰\n","ğŸš€ ê²½êµ¬ì•Œì•½ ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘\n","ğŸ“‚ ë¶„ì„ ê²½ë¡œ: data/\n","============================================================\n","ğŸ“ ë°ì´í„°ì…‹ êµ¬ì¡° ë¶„ì„\n","============================================================\n","âœ… Train ì´ë¯¸ì§€: 1,489ê°œ\n","ğŸ“ Train íŒŒì¼ëª… ìƒ˜í”Œ:\n","   K-003351-013900-036637_0_2_0_2_70_000_200\n","   K-003351-016232-018147_0_2_0_2_75_000_200\n","   K-003351-016232-019232_0_2_0_2_70_000_200\n","   K-003351-013900-035206_0_2_0_2_70_000_200\n","   K-003351-013900-035206_0_2_0_2_90_000_200\n","âœ… Test ì´ë¯¸ì§€: 843ê°œ\n","âœ… Train annotations í´ë” ì¡´ì¬\n","ğŸ“ ì´ JSON íŒŒì¼: 4,526ê°œ\n","ğŸ“‚ Annotation í•˜ìœ„ í´ë”: 498ê°œ\n","   ğŸ“ K-001900-016548-018110-021026_json/ (4ê°œ í•˜ìœ„í´ë”, 10ê°œ JSON)\n","   ğŸ“ K-001900-016548-018110-029451_json/ (4ê°œ í•˜ìœ„í´ë”, 10ê°œ JSON)\n","   ğŸ“ K-001900-016548-018110-031705_json/ (4ê°œ í•˜ìœ„í´ë”, 11ê°œ JSON)\n","   ... ì™¸ 495ê°œ í´ë”\n","\n","============================================================\n","ğŸ“ Annotation JSON ìƒ˜í”Œ ë¶„ì„ (3ê°œ)\n","============================================================\n","\n","ğŸ” ìƒ˜í”Œ 1: K-001900-016548-018110-021026_0_2_0_2_75_000_200.json\n","   ê²½ë¡œ: K-001900-016548-018110-021026_json/K-018110/K-001900-016548-018110-021026_0_2_0_2_75_000_200.json\n","   ğŸ“Š JSON êµ¬ì¡°:\n","      íƒ€ì…: <class 'dict'>\n","      í‚¤ë“¤: ['images', 'type', 'annotations', 'categories']\n","         images: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['file_name', 'width', 'height', 'imgfile', 'drug_N', 'drug_S', 'back_color', 'drug_dir', 'light_color', 'camera_la', 'camera_lo', 'size', 'dl_idx', 'dl_mapping_code', 'dl_name', 'dl_name_en', 'img_key', 'dl_material', 'dl_material_en', 'dl_custom_shape', 'dl_company', 'dl_company_en', 'di_company_mf', 'di_company_mf_en', 'item_seq', 'di_item_permit_date', 'di_class_no', 'di_etc_otc_code', 'di_edi_code', 'chart', 'drug_shape', 'thick', 'leng_long', 'leng_short', 'print_front', 'print_back', 'color_class1', 'color_class2', 'line_front', 'line_back', 'img_regist_ts', 'form_code_name', 'mark_code_front_anal', 'mark_code_back_anal', 'mark_code_front_img', 'mark_code_back_img', 'mark_code_front', 'mark_code_back', 'change_date', 'id']\n","         type: str = instances\n","         annotations: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['area', 'iscrowd', 'bbox', 'category_id', 'ignore', 'segmentation', 'id', 'image_id']\n","         categories: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['supercategory', 'id', 'name']\n","\n","ğŸ” ìƒ˜í”Œ 2: K-001900-016548-018110-021026_0_2_0_2_70_000_200.json\n","   ê²½ë¡œ: K-001900-016548-018110-021026_json/K-018110/K-001900-016548-018110-021026_0_2_0_2_70_000_200.json\n","   ğŸ“Š JSON êµ¬ì¡°:\n","      íƒ€ì…: <class 'dict'>\n","      í‚¤ë“¤: ['images', 'type', 'annotations', 'categories']\n","         images: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['file_name', 'width', 'height', 'imgfile', 'drug_N', 'drug_S', 'back_color', 'drug_dir', 'light_color', 'camera_la', 'camera_lo', 'size', 'dl_idx', 'dl_mapping_code', 'dl_name', 'dl_name_en', 'img_key', 'dl_material', 'dl_material_en', 'dl_custom_shape', 'dl_company', 'dl_company_en', 'di_company_mf', 'di_company_mf_en', 'item_seq', 'di_item_permit_date', 'di_class_no', 'di_etc_otc_code', 'di_edi_code', 'chart', 'drug_shape', 'thick', 'leng_long', 'leng_short', 'print_front', 'print_back', 'color_class1', 'color_class2', 'line_front', 'line_back', 'img_regist_ts', 'form_code_name', 'mark_code_front_anal', 'mark_code_back_anal', 'mark_code_front_img', 'mark_code_back_img', 'mark_code_front', 'mark_code_back', 'change_date', 'id']\n","         type: str = instances\n","         annotations: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['area', 'iscrowd', 'bbox', 'category_id', 'ignore', 'segmentation', 'id', 'image_id']\n","         categories: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['supercategory', 'id', 'name']\n","\n","ğŸ” ìƒ˜í”Œ 3: K-001900-016548-018110-021026_0_2_0_2_75_000_200.json\n","   ê²½ë¡œ: K-001900-016548-018110-021026_json/K-021026/K-001900-016548-018110-021026_0_2_0_2_75_000_200.json\n","   ğŸ“Š JSON êµ¬ì¡°:\n","      íƒ€ì…: <class 'dict'>\n","      í‚¤ë“¤: ['images', 'type', 'annotations', 'categories']\n","         images: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['file_name', 'width', 'height', 'imgfile', 'drug_N', 'drug_S', 'back_color', 'drug_dir', 'light_color', 'camera_la', 'camera_lo', 'size', 'dl_idx', 'dl_mapping_code', 'dl_name', 'dl_name_en', 'img_key', 'dl_material', 'dl_material_en', 'dl_custom_shape', 'dl_company', 'dl_company_en', 'di_company_mf', 'di_company_mf_en', 'item_seq', 'di_item_permit_date', 'di_class_no', 'di_etc_otc_code', 'di_edi_code', 'chart', 'drug_shape', 'thick', 'leng_long', 'leng_short', 'print_front', 'print_back', 'color_class1', 'color_class2', 'line_front', 'line_back', 'img_regist_ts', 'form_code_name', 'mark_code_front_anal', 'mark_code_back_anal', 'mark_code_front_img', 'mark_code_back_img', 'mark_code_front', 'mark_code_back', 'change_date', 'id']\n","         type: str = instances\n","         annotations: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['area', 'iscrowd', 'bbox', 'category_id', 'ignore', 'segmentation', 'id', 'image_id']\n","         categories: ë¦¬ìŠ¤íŠ¸ (1ê°œ)\n","            ì²« ìš”ì†Œ í‚¤: ['supercategory', 'id', 'name']\n","\n","============================================================\n","ğŸ”— ì´ë¯¸ì§€-Annotation ë§¤ì¹­ í™•ì¸\n","============================================================\n","ğŸ–¼ï¸  ì´ë¯¸ì§€ íŒŒì¼: 1,489ê°œ\n","ğŸ“ JSON íŒŒì¼: 1,489ê°œ\n","âœ… ë§¤ì¹­ë¨: 1,489ê°œ\n","ğŸ–¼ï¸  ì´ë¯¸ì§€ë§Œ ìˆìŒ: 0ê°œ\n","ğŸ“ JSONë§Œ ìˆìŒ: 0ê°œ\n","\n","============================================================\n","ğŸ“‚ Annotation í´ë” íŒ¨í„´ ë¶„ì„\n","============================================================\n","ğŸ“ 1ë‹¨ê³„ í´ë”: 498ê°œ\n","\n","ğŸ” K-001900-016548-018110-021026_json/\n","   ğŸ“ í•˜ìœ„ í´ë”: 4ê°œ\n","   ğŸ“ JSON íŒŒì¼: 10ê°œ\n","   ğŸ“‹ í•˜ìœ„ í´ë”ëª… ìƒ˜í”Œ: ['K-018110', 'K-021026', 'K-001900', 'K-016548']\n","      K-018110: 2ê°œ JSON\n","      K-021026: 2ê°œ JSON\n","      K-001900: 3ê°œ JSON\n","\n","ğŸ” K-001900-016548-018110-029451_json/\n","   ğŸ“ í•˜ìœ„ í´ë”: 4ê°œ\n","   ğŸ“ JSON íŒŒì¼: 10ê°œ\n","   ğŸ“‹ í•˜ìœ„ í´ë”ëª… ìƒ˜í”Œ: ['K-001900', 'K-016548', 'K-018110', 'K-029451']\n","      K-001900: 3ê°œ JSON\n","      K-016548: 3ê°œ JSON\n","      K-018110: 2ê°œ JSON\n","\n","ğŸ” K-001900-016548-018110-031705_json/\n","   ğŸ“ í•˜ìœ„ í´ë”: 4ê°œ\n","   ğŸ“ JSON íŒŒì¼: 11ê°œ\n","   ğŸ“‹ í•˜ìœ„ í´ë”ëª… ìƒ˜í”Œ: ['K-018110', 'K-031705', 'K-016548', 'K-001900']\n","      K-018110: 3ê°œ JSON\n","      K-031705: 3ê°œ JSON\n","      K-016548: 3ê°œ JSON\n","\n","============================================================\n","ğŸ“Š ë¶„ì„ ìš”ì•½\n","============================================================\n","âœ… Train ì´ë¯¸ì§€: 1,489ê°œ\n","âœ… Test ì´ë¯¸ì§€: 843ê°œ\n","âœ… Train annotations: 4,526ê°œ\n","ğŸ”— ë§¤ì¹­ë¥ : 100.0%\n","\n","âœ… ë¶„ì„ ì™„ë£Œ!\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"xBVUPywN7ARS","executionInfo":{"status":"ok","timestamp":1757481489499,"user_tz":-540,"elapsed":1709,"user":{"displayName":"ì§€ë™ì§„","userId":"11099336268482278400"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"EDA í´ë” êµ¬ì¡° ë° íŒŒì¼ ê°œìˆ˜ ë¶„ì„ MVP \""],"metadata":{"id":"Cy7TqcG-D0xv"},"execution_count":null,"outputs":[]}]}