{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCEBCvo9kbpu3J3Wwl0TUn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZ6-aojLv9n5","executionInfo":{"status":"ok","timestamp":1758188642192,"user_tz":-540,"elapsed":30204,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"7a1ae5a8-9325-47e5-c415-6beffe097084"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 1. 기존 리포지토리 폴더로 이동\n","import os\n","os.chdir('/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project')"],"metadata":{"id":"BqAio3Eiv_32","executionInfo":{"status":"ok","timestamp":1758188642574,"user_tz":-540,"elapsed":383,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 2. 경로 확인\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZVWjhkrwBXO","executionInfo":{"status":"ok","timestamp":1758188642840,"user_tz":-540,"elapsed":265,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"a9cb8190-ef9a-468c-c347-e3eab4b39b18"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"hZ-NOG0yvl8t","executionInfo":{"status":"ok","timestamp":1758188642842,"user_tz":-540,"elapsed":1,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"outputs":[],"source":["import os\n","import shutil\n","import json\n","import random\n","from pathlib import Path\n","from typing import Dict, List, Tuple\n","import glob"]},{"cell_type":"code","source":["def find_annotation_file(image_filename: str, annotations_root: str) -> str:\n","    \"\"\"\n","    이미지 파일명에 해당하는 annotation json 파일을 찾습니다.\n","    \"\"\"\n","    # 이미지 파일명에서 확장자를 제거하고 .json을 붙임\n","    json_filename = image_filename.replace('.png', '.json').replace('.jpg', '.json')\n","\n","    # annotations_root에서 해당 json 파일을 재귀적으로 찾기\n","    pattern = os.path.join(annotations_root, '**', json_filename)\n","    matches = glob.glob(pattern, recursive=True)\n","\n","    if matches:\n","        return matches[0]  # 첫 번째 매치를 반환\n","    else:\n","        return None"],"metadata":{"id":"6TP0v1wvvsZC","executionInfo":{"status":"ok","timestamp":1758188642844,"user_tz":-540,"elapsed":1,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def create_dataset_subset(\n","    source_dir: str,\n","    target_dir: str,\n","    subset_name: str,\n","    num_samples: int,\n","    seed: int = 42\n",") -> Dict[str, int]:\n","    \"\"\"\n","    원본 데이터셋에서 지정된 수만큼 샘플을 추출하여 새로운 데이터셋을 생성합니다.\n","\n","    Args:\n","        source_dir: 원본 데이터셋 경로\n","        target_dir: 생성될 서브셋 데이터셋 경로\n","        subset_name: 서브셋 이름 (small, medium, large)\n","        num_samples: 추출할 샘플 수\n","        seed: 랜덤 시드\n","\n","    Returns:\n","        생성된 파일 수 정보가 담긴 딕셔너리\n","    \"\"\"\n","    random.seed(seed)\n","\n","    # 경로 설정\n","    train_images_dir = os.path.join(source_dir, 'train_images')\n","    train_annotations_dir = os.path.join(source_dir, 'train_annotations')\n","    test_images_dir = os.path.join(source_dir, 'test_images')\n","\n","    # 타겟 디렉토리 생성\n","    target_subset_dir = os.path.join(target_dir, f'dataset_{subset_name}')\n","    target_train_images = os.path.join(target_subset_dir, 'train_images')\n","    target_train_annotations = os.path.join(target_subset_dir, 'train_annotations')\n","    target_test_images = os.path.join(target_subset_dir, 'test_images')\n","\n","    # 디렉토리 생성\n","    os.makedirs(target_train_images, exist_ok=True)\n","    os.makedirs(target_train_annotations, exist_ok=True)\n","    os.makedirs(target_test_images, exist_ok=True)\n","\n","    # train 이미지 파일 목록 가져오기\n","    train_image_files = []\n","    for ext in ['*.png', '*.jpg', '*.jpeg']:\n","        train_image_files.extend(glob.glob(os.path.join(train_images_dir, ext)))\n","\n","    print(f\"총 {len(train_image_files)}개의 train 이미지를 찾았습니다.\")\n","\n","    # 랜덤하게 샘플 선택\n","    if num_samples > len(train_image_files):\n","        print(f\"경고: 요청한 샘플 수({num_samples})가 전체 데이터 수({len(train_image_files)})보다 큽니다.\")\n","        num_samples = len(train_image_files)\n","\n","    selected_images = random.sample(train_image_files, num_samples)\n","\n","    # 통계\n","    stats = {\n","        'copied_images': 0,\n","        'copied_annotations': 0,\n","        'missing_annotations': 0,\n","        'copied_test_images': 0\n","    }\n","\n","    print(f\"\\n{subset_name} 데이터셋 생성 중... ({num_samples}개 샘플)\")\n","\n","    # 선택된 이미지들과 해당 어노테이션 복사\n","    for img_path in selected_images:\n","        img_filename = os.path.basename(img_path)\n","\n","        # 이미지 복사\n","        target_img_path = os.path.join(target_train_images, img_filename)\n","        shutil.copy2(img_path, target_img_path)\n","        stats['copied_images'] += 1\n","\n","        # 해당하는 어노테이션 파일 찾기\n","        annotation_path = find_annotation_file(img_filename, train_annotations_dir)\n","\n","        if annotation_path:\n","            # 원본 어노테이션 폴더 구조 유지\n","            # 예: train_annotations/K-003544-010221-016551-027926_json/K-003544/file.json\n","            rel_path = os.path.relpath(annotation_path, train_annotations_dir)\n","            target_annotation_path = os.path.join(target_train_annotations, rel_path)\n","\n","            # 타겟 디렉토리 생성\n","            os.makedirs(os.path.dirname(target_annotation_path), exist_ok=True)\n","\n","            # 어노테이션 파일 복사\n","            shutil.copy2(annotation_path, target_annotation_path)\n","            stats['copied_annotations'] += 1\n","        else:\n","            print(f\"경고: {img_filename}에 해당하는 어노테이션 파일을 찾을 수 없습니다.\")\n","            stats['missing_annotations'] += 1\n","\n","    # 테스트 이미지들도 모두 복사 (전체 테스트 세트 유지)\n","    if os.path.exists(test_images_dir):\n","        for test_img in glob.glob(os.path.join(test_images_dir, '*')):\n","            if os.path.isfile(test_img):\n","                shutil.copy2(test_img, os.path.join(target_test_images, os.path.basename(test_img)))\n","                stats['copied_test_images'] += 1\n","\n","    return stats"],"metadata":{"id":"JOcaG0Txvu1h","executionInfo":{"status":"ok","timestamp":1758188642858,"user_tz":-540,"elapsed":4,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def create_all_subsets(source_dir: str, target_dir: str, configs: Dict[str, int]):\n","    \"\"\"\n","    모든 서브셋을 생성합니다.\n","\n","    Args:\n","        source_dir: 원본 데이터셋 경로\n","        target_dir: 생성될 서브셋 데이터셋 경로\n","        configs: {subset_name: num_samples} 형태의 딕셔너리\n","    \"\"\"\n","    print(\"=\"*60)\n","    print(\"데이터셋 분할 시작\")\n","    print(\"=\"*60)\n","\n","    total_stats = {}\n","\n","    for subset_name, num_samples in configs.items():\n","        print(f\"\\n[{subset_name.upper()}] 데이터셋 생성 중...\")\n","        stats = create_dataset_subset(source_dir, target_dir, subset_name, num_samples)\n","        total_stats[subset_name] = stats\n","\n","        print(f\"✅ {subset_name} 데이터셋 완성!\")\n","        print(f\"   - 이미지: {stats['copied_images']}개\")\n","        print(f\"   - 어노테이션: {stats['copied_annotations']}개\")\n","        print(f\"   - 테스트 이미지: {stats['copied_test_images']}개\")\n","        if stats['missing_annotations'] > 0:\n","            print(f\"   - 누락된 어노테이션: {stats['missing_annotations']}개\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"모든 데이터셋 분할 완료!\")\n","    print(\"=\"*60)\n","\n","    return total_stats"],"metadata":{"id":"UUpp4dX_vy-6","executionInfo":{"status":"ok","timestamp":1758188642881,"user_tz":-540,"elapsed":1,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def create_percentage_based_subsets(source_dir: str, target_dir: str, percentages: List[Tuple[str, float]]):\n","    \"\"\"\n","    비율 기반으로 데이터셋 서브셋들을 생성합니다.\n","\n","    Args:\n","        source_dir: 원본 데이터셋 경로\n","        target_dir: 생성될 서브셋 데이터셋 경로\n","        percentages: [(subset_name, percentage), ...] 형태의 리스트\n","                    예: [(\"nano\", 0.1), (\"small\", 0.2), (\"medium\", 0.5), (\"large\", 0.8)]\n","    \"\"\"\n","    # 원본 train 이미지 수 확인\n","    train_images_dir = os.path.join(source_dir, 'train_images')\n","    train_image_files = []\n","    for ext in ['*.png', '*.jpg', '*.jpeg']:\n","        train_image_files.extend(glob.glob(os.path.join(train_images_dir, ext)))\n","\n","    total_train_images = len(train_image_files)\n","\n","    print(f\"원본 Train 이미지 수: {total_train_images}개\")\n","\n","    # 비율에 따른 데이터셋 크기 계산\n","    dataset_configs = {}\n","    print(f\"\\n생성될 데이터셋 크기:\")\n","    for name, percentage in percentages:\n","        size = int(total_train_images * percentage)\n","        dataset_configs[name] = size\n","        print(f\"  - {name}: {size}개 ({percentage*100:.0f}%)\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"비율 기반 데이터셋 분할 시작\")\n","    print(\"=\"*60)\n","\n","    # 모든 서브셋 생성\n","    return create_all_subsets(source_dir, target_dir, dataset_configs)"],"metadata":{"id":"WuUzhN_hv2d7","executionInfo":{"status":"ok","timestamp":1758188642908,"user_tz":-540,"elapsed":2,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # 설정\n","    SOURCE_DATA_DIR = \"./data\"  # 원본 데이터 경로 (Colab 기준)\n","    TARGET_DATA_DIR = \"./data/datasets\"  # 생성될 데이터셋들의 상위 경로\n","\n","    # 타겟 디렉토리 생성\n","    os.makedirs(TARGET_DATA_DIR, exist_ok=True)\n","\n","    # 방법 1: 비율 기반으로 생성 (권장)\n","    percentages = [\n","        (\"nano\", 0.1),    # 10%\n","        (\"small\", 0.2),   # 20%\n","        (\"medium\", 0.5),  # 50%\n","        (\"large\", 0.8)    # 80%\n","    ]\n","\n","    results = create_percentage_based_subsets(SOURCE_DATA_DIR, TARGET_DATA_DIR, percentages)\n","\n","    # 최종 결과 출력\n","    print(\"\\n📊 최종 통계:\")\n","    for subset_name, stats in results.items():\n","        print(f\"{subset_name}: {stats['copied_images']}개 이미지, {stats['copied_annotations']}개 어노테이션\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":719},"id":"u3qQUwO-wJh8","executionInfo":{"status":"error","timestamp":1758188655629,"user_tz":-540,"elapsed":12681,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"c08a57d5-4451-4f40-e80d-5e0f90f9ae07"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["원본 Train 이미지 수: 1489개\n","\n","생성될 데이터셋 크기:\n","  - nano: 148개 (10%)\n","  - small: 297개 (20%)\n","  - medium: 744개 (50%)\n","  - large: 1191개 (80%)\n","\n","============================================================\n","비율 기반 데이터셋 분할 시작\n","============================================================\n","============================================================\n","데이터셋 분할 시작\n","============================================================\n","\n","[NANO] 데이터셋 생성 중...\n","총 1489개의 train 이미지를 찾았습니다.\n","\n","nano 데이터셋 생성 중... (148개 샘플)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2351241556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     ]\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_percentage_based_subsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTARGET_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# 최종 결과 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4070335557.py\u001b[0m in \u001b[0;36mcreate_percentage_based_subsets\u001b[0;34m(source_dir, target_dir, percentages)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# 모든 서브셋 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_all_subsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-869893784.py\u001b[0m in \u001b[0;36mcreate_all_subsets\u001b[0;34m(source_dir, target_dir, configs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[{subset_name.upper()}] 데이터셋 생성 중...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtotal_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2046105265.py\u001b[0m in \u001b[0;36mcreate_dataset_subset\u001b[0;34m(source_dir, target_dir, subset_name, num_samples, seed)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# 해당하는 어노테이션 파일 찾기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mannotation_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_annotation_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_annotations_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mannotation_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-856894199.py\u001b[0m in \u001b[0;36mfind_annotation_file\u001b[0;34m(image_filename, annotations_root)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# annotations_root에서 해당 json 파일을 재귀적으로 찾기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'**'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, root_dir, dir_fd, recursive, include_hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     return list(iglob(pathname, root_dir=root_dir, dir_fd=dir_fd, recursive=recursive,\n\u001b[0m\u001b[1;32m     29\u001b[0m                       include_hidden=include_hidden))\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, root_dir, dir_fd, recursive, dironly, include_hidden)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         for name in glob_in_dir(_join(root_dir, dirname), basename, dir_fd, dironly,\n\u001b[0m\u001b[1;32m     98\u001b[0m                                include_hidden=include_hidden):\n\u001b[1;32m     99\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## 데이터셋 생성 시간\n","1. NANO: 12분\n","2. SMALL: 14분\n","3. MEDIUM: 28분\n","4. LARGE: 34분"],"metadata":{"id":"N_TlUZE22ulP"}},{"cell_type":"code","source":[],"metadata":{"id":"57Mjz4gvyKA3","executionInfo":{"status":"aborted","timestamp":1758188655663,"user_tz":-540,"elapsed":31,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":null,"outputs":[]}]}