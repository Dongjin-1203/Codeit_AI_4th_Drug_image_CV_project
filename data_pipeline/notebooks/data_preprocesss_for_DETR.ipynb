{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0ijAJdmXnC7wn6SByPkFl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4Ka4stKIdOl","executionInfo":{"status":"ok","timestamp":1758188698476,"user_tz":-540,"elapsed":21106,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"2093e63a-2337-4bd0-f6cb-2def072e7da3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# 1. 기존 리포지토리 폴더로 이동\n","import os\n","os.chdir('/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project')"],"metadata":{"id":"s4gY-S2xJqmq","executionInfo":{"status":"ok","timestamp":1758188699120,"user_tz":-540,"elapsed":642,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 2. 경로 확인\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MU2GQgcNJ06a","executionInfo":{"status":"ok","timestamp":1758188699236,"user_tz":-540,"elapsed":108,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"896cc1c6-c6f5-447c-d265-7f6b39223b63"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Codeit_AI_4th_Drug_image_CV_project\n"]}]},{"cell_type":"code","source":["# 3. 최신 변경사항 가져오기\n","!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lq2aorjXMNI4","executionInfo":{"status":"ok","timestamp":1758188786585,"user_tz":-540,"elapsed":87339,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"6eb404ed-a6ca-403b-d03d-bfbab13afd70"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 8, done.\u001b[K\n","remote: Counting objects:  12% (1/8)\u001b[K\rremote: Counting objects:  25% (2/8)\u001b[K\rremote: Counting objects:  37% (3/8)\u001b[K\rremote: Counting objects:  50% (4/8)\u001b[K\rremote: Counting objects:  62% (5/8)\u001b[K\rremote: Counting objects:  75% (6/8)\u001b[K\rremote: Counting objects:  87% (7/8)\u001b[K\rremote: Counting objects: 100% (8/8)\u001b[K\rremote: Counting objects: 100% (8/8), done.\u001b[K\n","remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 6 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects: 100% (6/6), 1.96 KiB | 1024 bytes/s, done.\n","From https://github.com/Dongjin-1203/Codeit_AI_4th_Drug_image_CV_project\n"," * branch            main       -> FETCH_HEAD\n","   57fbabb..e460a65  main       -> origin/main\n","Updating 57fbabb..e460a65\n","Fast-forward\n"," .gitignore | 5 \u001b[32m++++\u001b[m\u001b[31m-\u001b[m\n"," 1 file changed, 4 insertions(+), 1 deletion(-)\n"]}]},{"cell_type":"code","source":["# 3. 현재 상태 확인\n","!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGbfgh1zMRU4","executionInfo":{"status":"ok","timestamp":1758188788037,"user_tz":-540,"elapsed":1451,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"caa12d5e-4fce-4df6-b100-31cfd76be039"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   notebooks/data_EDA.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mdata_pipeline/notebooks/\u001b[m\n","\t\u001b[31mnotebooks/New_split_dataset.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"markdown","source":["# DETR 전용 데이터 전처리 코드"],"metadata":{"id":"fI35z4dgMonK"}},{"cell_type":"markdown","source":["## 초기 설정"],"metadata":{"id":"KU_5hJawNXKe"}},{"cell_type":"code","source":["import os\n","import json\n","import shutil\n","from collections import defaultdict\n","from datetime import datetime\n","import glob\n","from PIL import Image"],"metadata":{"id":"LnPcXbS6MnhA","executionInfo":{"status":"ok","timestamp":1758189061060,"user_tz":-540,"elapsed":3,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class DETR_preprocessor:\n","    def __init__(self, data_path = \"./data\"):\n","        self.data_path = data_path\n","        self.test_images_path = os.path.join(data_path, \"test_images\")\n","        self.train_images_path = os.path.join(data_path, \"train_images\")\n","        self.train_ann_path = os.path.join(data_path, \"train_annotations\")\n","\n","        # 출력 디렉토리\n","        self.output_dir = os.path.join(data_path, \"processed\")\n","        os.makedirs(self.output_dir, exist_ok=True)\n","\n","    def find_all_json_files(self):\n","        \"\"\"\n","        train_annotations 디렉토리에서 모든 JSON 파일을 찾기\n","        \"\"\"\n","        pattern = os.path.join(self.train_ann_path, \"**\", \"*.json\")\n","        json_files = glob.glob(pattern, recursive=True)\n","\n","        print(f\"총 {len(json_files)}개의 JSON 파일을 찾았습니다.\")\n","        return json_files\n","\n","    # DETR은 하나의 JSON파일을 사용한다.\n","    def merge_coco_annotations(self, json_files):\n","        \"\"\"\n","        여러 COCO 포맷 JSON 파일들을 하나로 병합\n","        - 동일한 알약의 다른 인스턴스들은 모두 보존\n","        - 카테고리는 이름 기준으로 통일\n","        \"\"\"\n","        merged_data = {\n","            \"images\": [],\n","            \"annotations\": [],\n","            \"categories\": [],\n","            \"info\": {\n","                \"description\": \"Merged Pill Dataset\",\n","                \"version\": \"1.0\",\n","                \"year\": 2024,\n","                \"date_created\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            }\n","        }\n","\n","        # ID 재할당을 위한 카운터\n","        new_image_id = 1\n","        new_annotation_id = 1\n","\n","        # 카테고리 통합 (이름 기준)\n","        category_name_to_new_id = {}\n","        new_category_id = 1\n","\n","        # 중복 이미지 파일 추적 (파일명 기준)\n","        processed_filenames = set()\n","\n","        print(\"COCO 포맷 JSON 파일들을 병합하는 중...\")\n","\n","        for i, json_file in enumerate(json_files):\n","            try:\n","                with open(json_file, 'r', encoding='utf-8') as f:\n","                    data = json.load(f)\n","\n","                print(f\"처리 중: {os.path.basename(json_file)} ({i+1}/{len(json_files)})\")\n","\n","                # 1. 카테고리 병합 및 ID 매핑 생성\n","                original_to_new_category_id = {}\n","\n","                if 'categories' in data:\n","                    for category in data['categories']:\n","                        cat_name = category['name']\n","                        original_cat_id = category['id']\n","\n","                        if cat_name not in category_name_to_new_id:\n","                            # 새로운 카테고리 추가\n","                            new_category = {\n","                                \"id\": new_category_id,\n","                                \"name\": cat_name,\n","                                \"supercategory\": category.get('supercategory', 'pill')\n","                            }\n","                            merged_data['categories'].append(new_category)\n","                            category_name_to_new_id[cat_name] = new_category_id\n","                            original_to_new_category_id[original_cat_id] = new_category_id\n","                            new_category_id += 1\n","                        else:\n","                            # 기존 카테고리 ID 매핑\n","                            original_to_new_category_id[original_cat_id] = category_name_to_new_id[cat_name]\n","\n","                # 2. 이미지 처리 및 ID 매핑 생성\n","                original_to_new_image_id = {}\n","\n","                if 'images' in data:\n","                    for image in data['images']:\n","                        filename = image['file_name']\n","                        original_img_id = image['id']\n","\n","                        # 이미지 파일 존재 확인\n","                        img_path = os.path.join(self.train_images_path, filename)\n","                        if not os.path.exists(img_path):\n","                            print(f\"경고: 이미지 파일이 없습니다 - {filename}\")\n","                            continue\n","\n","                        # 파일명 중복 체크 (같은 파일은 한 번만 추가)\n","                        if filename in processed_filenames:\n","                            print(f\"중복 파일명 스킵: {filename}\")\n","                            # 하지만 ID 매핑은 유지해야 함\n","                            for existing_img in merged_data['images']:\n","                                if existing_img['file_name'] == filename:\n","                                    original_to_new_image_id[original_img_id] = existing_img['id']\n","                                    break\n","                            continue\n","\n","                        # 새로운 이미지 추가\n","                        new_image = image.copy()\n","                        new_image['id'] = new_image_id\n","                        merged_data['images'].append(new_image)\n","\n","                        original_to_new_image_id[original_img_id] = new_image_id\n","                        processed_filenames.add(filename)\n","                        new_image_id += 1\n","\n","                # 3. 어노테이션 처리 (모든 인스턴스 보존)\n","                if 'annotations' in data:\n","                    for annotation in data['annotations']:\n","                        original_img_id = annotation['image_id']\n","                        original_cat_id = annotation['category_id']\n","\n","                        # ID 매핑 확인\n","                        if (original_img_id in original_to_new_image_id and\n","                            original_cat_id in original_to_new_category_id):\n","\n","                            new_annotation = annotation.copy()\n","                            new_annotation['id'] = new_annotation_id\n","                            new_annotation['image_id'] = original_to_new_image_id[original_img_id]\n","                            new_annotation['category_id'] = original_to_new_category_id[original_cat_id]\n","\n","                            merged_data['annotations'].append(new_annotation)\n","                            new_annotation_id += 1\n","                        else:\n","                            print(f\"경고: 매핑되지 않은 어노테이션 - img_id: {original_img_id}, cat_id: {original_cat_id}\")\n","\n","            except Exception as e:\n","                print(f\"오류 발생 (파일: {json_file}): {e}\")\n","                continue\n","\n","        print(f\"\\n병합 완료:\")\n","        print(f\"  - 이미지: {len(merged_data['images'])}개\")\n","        print(f\"  - 어노테이션: {len(merged_data['annotations'])}개\")\n","        print(f\"  - 카테고리: {len(merged_data['categories'])}개\")\n","\n","        return merged_data\n","\n","    def validate_merged_data(self, merged_data):\n","        \"\"\"\n","        병합된 데이터의 무결성 검증\n","        \"\"\"\n","        print(\"\\n=== 데이터 무결성 검증 ===\")\n","\n","        # 이미지 ID 중복 체크\n","        image_ids = [img['id'] for img in merged_data['images']]\n","        if len(image_ids) != len(set(image_ids)):\n","            print(\"경고: 이미지 ID 중복이 있습니다!\")\n","            return False\n","\n","        # 어노테이션 ID 중복 체크\n","        ann_ids = [ann['id'] for ann in merged_data['annotations']]\n","        if len(ann_ids) != len(set(ann_ids)):\n","            print(\"경고: 어노테이션 ID 중복이 있습니다!\")\n","            return False\n","\n","        # 카테고리 ID 중복 체크\n","        cat_ids = [cat['id'] for cat in merged_data['categories']]\n","        if len(cat_ids) != len(set(cat_ids)):\n","            print(\"경고: 카테고리 ID 중복이 있습니다!\")\n","            return False\n","\n","        # 참조 무결성 체크\n","        valid_image_ids = set(img['id'] for img in merged_data['images'])\n","        valid_cat_ids = set(cat['id'] for cat in merged_data['categories'])\n","\n","        invalid_refs = 0\n","        for ann in merged_data['annotations']:\n","            if ann['image_id'] not in valid_image_ids:\n","                print(f\"경고: 존재하지 않는 image_id 참조: {ann['image_id']}\")\n","                invalid_refs += 1\n","            if ann['category_id'] not in valid_cat_ids:\n","                print(f\"경고: 존재하지 않는 category_id 참조: {ann['category_id']}\")\n","                invalid_refs += 1\n","\n","        if invalid_refs == 0:\n","            print(\"✓ 데이터 무결성 검증 통과!\")\n","            return True\n","        else:\n","            print(f\"경고: {invalid_refs}개의 참조 오류가 있습니다!\")\n","            return False\n","\n","    def create_train_val_split(self, merged_data, val_ratio=0.2):\n","        \"\"\"\n","        훈련/검증 데이터 분할\n","        \"\"\"\n","        import random\n","\n","        images = merged_data['images'].copy()\n","        annotations = merged_data['annotations']\n","        categories = merged_data['categories']\n","\n","        # 이미지 셔플\n","        random.seed(42)\n","        random.shuffle(images)\n","\n","        # 분할\n","        total_images = len(images)\n","        val_size = int(total_images * val_ratio)\n","\n","        val_images = images[:val_size]\n","        train_images = images[val_size:]\n","\n","        # 이미지 ID 집합\n","        train_image_ids = set(img['id'] for img in train_images)\n","        val_image_ids = set(img['id'] for img in val_images)\n","\n","        # 어노테이션 분할\n","        train_annotations = [ann for ann in annotations if ann['image_id'] in train_image_ids]\n","        val_annotations = [ann for ann in annotations if ann['image_id'] in val_image_ids]\n","\n","        # 데이터셋 구성\n","        train_data = {\n","            \"images\": train_images,\n","            \"annotations\": train_annotations,\n","            \"categories\": categories,\n","            \"info\": merged_data['info']\n","        }\n","\n","        val_data = {\n","            \"images\": val_images,\n","            \"annotations\": val_annotations,\n","            \"categories\": categories,\n","            \"info\": merged_data['info']\n","        }\n","\n","        print(f\"\\n데이터 분할 완료:\")\n","        print(f\"  훈련: 이미지 {len(train_images)}개, 어노테이션 {len(train_annotations)}개\")\n","        print(f\"  검증: 이미지 {len(val_images)}개, 어노테이션 {len(val_annotations)}개\")\n","\n","        return train_data, val_data\n","\n","    def copy_images_to_output(self):\n","        \"\"\"\n","        이미지 파일들을 출력 디렉토리로 복사\n","        \"\"\"\n","        print(\"이미지 파일들을 복사하는 중...\")\n","\n","        # 훈련 이미지 복사\n","        train_output_dir = os.path.join(self.output_dir, \"images\")\n","        os.makedirs(train_output_dir, exist_ok=True)\n","\n","        copied_count = 0\n","        if os.path.exists(self.train_images_path):\n","            for img_file in os.listdir(self.train_images_path):\n","                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n","                    src = os.path.join(self.train_images_path, img_file)\n","                    dst = os.path.join(train_output_dir, img_file)\n","                    shutil.copy2(src, dst)\n","                    copied_count += 1\n","\n","        print(f\"훈련 이미지 {copied_count}개 복사 완료\")\n","\n","        # 테스트 이미지 복사\n","        if os.path.exists(self.test_images_path):\n","            test_output_dir = os.path.join(self.output_dir, \"test_images\")\n","            os.makedirs(test_output_dir, exist_ok=True)\n","\n","            test_count = 0\n","            for img_file in os.listdir(self.test_images_path):\n","                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n","                    src = os.path.join(self.test_images_path, img_file)\n","                    dst = os.path.join(test_output_dir, img_file)\n","                    shutil.copy2(src, dst)\n","                    test_count += 1\n","\n","            print(f\"테스트 이미지 {test_count}개 복사 완료\")\n","\n","    def save_annotations(self, train_data, val_data, full_data):\n","        \"\"\"\n","        COCO 포맷 어노테이션 파일 저장\n","        \"\"\"\n","        # 전체 데이터\n","        with open(os.path.join(self.output_dir, \"annotations_full.json\"), 'w', encoding='utf-8') as f:\n","            json.dump(full_data, f, ensure_ascii=False, indent=2)\n","\n","        # 훈련 데이터\n","        with open(os.path.join(self.output_dir, \"annotations_train.json\"), 'w', encoding='utf-8') as f:\n","            json.dump(train_data, f, ensure_ascii=False, indent=2)\n","\n","        # 검증 데이터\n","        with open(os.path.join(self.output_dir, \"annotations_val.json\"), 'w', encoding='utf-8') as f:\n","            json.dump(val_data, f, ensure_ascii=False, indent=2)\n","\n","        print(\"\\n어노테이션 파일 저장 완료:\")\n","        print(f\"  - annotations_full.json: 전체 데이터\")\n","        print(f\"  - annotations_train.json: 훈련 분할\")\n","        print(f\"  - annotations_val.json: 검증 분할\")\n","\n","    def generate_dataset_statistics(self, data):\n","        \"\"\"\n","        데이터셋 통계 생성\n","        \"\"\"\n","        print(\"\\n=== 데이터셋 통계 ===\")\n","        print(f\"총 이미지 수: {len(data['images'])}\")\n","        print(f\"총 어노테이션 수: {len(data['annotations'])}\")\n","        print(f\"총 카테고리 수: {len(data['categories'])}\")\n","\n","        # 카테고리별 통계\n","        category_counts = defaultdict(int)\n","        category_names = {cat['id']: cat['name'] for cat in data['categories']}\n","\n","        for ann in data['annotations']:\n","            category_counts[ann['category_id']] += 1\n","\n","        print(f\"\\n카테고리별 어노테이션 수 (알약 종류별 인스턴스 수):\")\n","        for cat_id, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\n","            cat_name = category_names.get(cat_id, f\"Unknown({cat_id})\")\n","            print(f\"  {cat_name}: {count}개 인스턴스\")\n","\n","        # 이미지당 평균 객체 수\n","        if data['images']:\n","            avg_objects_per_image = len(data['annotations']) / len(data['images'])\n","            print(f\"\\n이미지당 평균 객체 수: {avg_objects_per_image:.2f}개\")\n","\n","        # 이미지 크기 통계\n","        if data['images']:\n","            widths = [img['width'] for img in data['images'] if 'width' in img]\n","            heights = [img['height'] for img in data['images'] if 'height' in img]\n","\n","            if widths and heights:\n","                print(f\"\\n이미지 크기 통계:\")\n","                print(f\"  너비: 최소 {min(widths)}, 최대 {max(widths)}, 평균 {sum(widths)/len(widths):.1f}\")\n","                print(f\"  높이: 최소 {min(heights)}, 최대 {max(heights)}, 평균 {sum(heights)/len(heights):.1f}\")\n","\n","    def process_dataset(self, create_splits=True, val_ratio=0.2):\n","        \"\"\"\n","        전체 전처리 파이프라인 실행\n","        \"\"\"\n","        print(\"=== COCO 포맷 알약 데이터셋 병합 시작 ===\")\n","\n","        # 1. JSON 파일들 찾기\n","        json_files = self.find_all_json_files()\n","\n","        if not json_files:\n","            print(\"JSON 파일을 찾을 수 없습니다!\")\n","            return None\n","\n","        # 2. COCO 어노테이션 병합\n","        merged_data = self.merge_coco_annotations(json_files)\n","\n","        # 3. 데이터 무결성 검증\n","        if not self.validate_merged_data(merged_data):\n","            print(\"데이터 무결성 검증 실패!\")\n","            return None\n","\n","        # 4. 이미지 파일 복사\n","        self.copy_images_to_output()\n","\n","        # 5. 훈련/검증 분할 (옵션)\n","        if create_splits and len(merged_data['images']) > 1:\n","            train_data, val_data = self.create_train_val_split(merged_data, val_ratio)\n","            self.save_annotations(train_data, val_data, merged_data)\n","        else:\n","            # 분할 없이 전체 데이터만 저장\n","            with open(os.path.join(self.output_dir, \"annotations.json\"), 'w', encoding='utf-8') as f:\n","                json.dump(merged_data, f, ensure_ascii=False, indent=2)\n","            print(\"전체 데이터를 annotations.json으로 저장했습니다.\")\n","\n","        # 6. 통계 생성\n","        self.generate_dataset_statistics(merged_data)\n","\n","        print(f\"\\n병합 완료! 결과는 '{self.output_dir}' 디렉토리에 저장되었습니다.\")\n","\n","        return merged_data"],"metadata":{"id":"SjXUUvWKNbQX","executionInfo":{"status":"ok","timestamp":1758189061610,"user_tz":-540,"elapsed":65,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## 메인 실행 함수"],"metadata":{"id":"sw2il22yc_8i"}},{"cell_type":"code","source":["def main():\n","    preprocessor = DETR_preprocessor(data_path = \"./data/datasets/dataset_nano\")\n","\n","    # 전체 병합 실행\n","    dataset = preprocessor.process_dataset(\n","        create_splits=True,  # 훈련/검증 분할 여부\n","        val_ratio=0.2       # 검증 데이터 비율 (20%)\n","    )\n","    print(\"\\n처리된 파일 구조:\")\n","    print(\"./data/processed/\")\n","    print(\"├── images/                    # 모든 훈련 이미지 파일\")\n","    print(\"├── test_images/               # 테스트 이미지 (있는 경우)\")\n","    print(\"├── annotations_full.json     # 전체 데이터\")\n","    print(\"├── annotations_train.json    # 훈련 분할\")\n","    print(\"└── annotations_val.json      # 검증 분할\")"],"metadata":{"id":"J3Yx1vh7c_YT","executionInfo":{"status":"ok","timestamp":1758189063826,"user_tz":-540,"elapsed":11,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CIiK5EqsdeWB","executionInfo":{"status":"ok","timestamp":1758189533788,"user_tz":-540,"elapsed":468208,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"d7ca4fe3-eff6-402c-dfa0-7b9c9a55ac78"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["=== COCO 포맷 알약 데이터셋 병합 시작 ===\n","총 148개의 JSON 파일을 찾았습니다.\n","COCO 포맷 JSON 파일들을 병합하는 중...\n","처리 중: K-002483-004378-023223-025438_0_2_0_2_70_000_200.json (1/148)\n","처리 중: K-003351-033880-038162_0_2_0_2_75_000_200.json (2/148)\n","처리 중: K-003351-016262-018147_0_2_0_2_70_000_200.json (3/148)\n","처리 중: K-003483-020238-025469-031885_0_2_0_2_90_000_200.json (4/148)\n","처리 중: K-003483-019861-022347-035206_0_2_0_2_90_000_200.json (5/148)\n","처리 중: K-003483-016262-027777-031885_0_2_0_2_70_000_200.json (6/148)\n","처리 중: K-003483-016232-019861-028763_0_2_0_2_75_000_200.json (7/148)\n","처리 중: K-003351-022074-032310_0_2_0_2_75_000_200.json (8/148)\n","처리 중: K-002483-005094-013395-023223_0_2_0_2_70_000_200.json (9/148)\n","처리 중: K-001900-016548-027926-044199_0_2_0_2_70_000_200.json (10/148)\n","처리 중: K-001900-016548-027926-044199_0_2_0_2_90_000_200.json (11/148)\n","처리 중: K-003351-020014-029667_0_2_0_2_90_000_200.json (12/148)\n","처리 중: K-001900-016551-024850-031705_0_2_0_2_75_000_200.json (13/148)\n","처리 중: K-003483-027777-029667-030308_0_2_0_2_90_000_200.json (14/148)\n","처리 중: K-003351-016688-018357_0_2_0_2_70_000_200.json (15/148)\n","처리 중: K-003351-016262-041768_0_2_0_2_75_000_200.json (16/148)\n","처리 중: K-003351-022074-031863_0_2_0_2_75_000_200.json (17/148)\n","처리 중: K-003483-016262-027733-034597_0_2_0_2_90_000_200.json (18/148)\n","처리 중: K-003483-019861-022347-029667_0_2_0_2_75_000_200.json (19/148)\n","처리 중: K-001900-016548-019607-021026_0_2_0_2_90_000_200.json (20/148)\n","처리 중: K-002483-003743-005886-012778_0_2_0_2_75_000_200.json (21/148)\n","처리 중: K-003351-016262-019232_0_2_0_2_90_000_200.json (22/148)\n","처리 중: K-001900-016551-019607-031705_0_2_0_2_90_000_200.json (23/148)\n","처리 중: K-003483-016262-027653-028763_0_2_0_2_70_000_200.json (24/148)\n","처리 중: K-003483-016262-027653-028763_0_2_0_2_75_000_200.json (25/148)\n","처리 중: K-003351-003832-021325_0_2_0_2_70_000_200.json (26/148)\n","처리 중: K-002483-005094-005886-012778_0_2_0_2_70_000_200.json (27/148)\n","처리 중: K-002483-012778-013395-025438_0_2_0_2_75_000_200.json (28/148)\n","처리 중: K-003483-027777-030308-036637_0_2_0_2_90_000_200.json (29/148)\n","처리 중: K-003483-019861-020238-025367_0_2_0_2_70_000_200.json (30/148)\n","처리 중: K-003544-006563-012247-016548_0_2_0_2_75_000_200.json (31/148)\n","처리 중: K-001900-016551-029345-044199_0_2_0_2_75_000_200.json (32/148)\n","처리 중: K-003483-020238-022347-027777_0_2_0_2_75_000_200.json (33/148)\n","처리 중: K-003351-013900-022074_0_2_0_2_90_000_200.json (34/148)\n","처리 중: K-003483-016232-027653-034597_0_2_0_2_90_000_200.json (35/148)\n","처리 중: K-003351-003832-016232_0_2_0_2_90_000_200.json (36/148)\n","처리 중: K-003483-027777-028763-036637_0_2_0_2_90_000_200.json (37/148)\n","처리 중: K-003483-022347-027733-029667_0_2_0_2_90_000_200.json (38/148)\n","처리 중: K-003483-016232-025469-031885_0_2_0_2_90_000_200.json (39/148)\n","처리 중: K-003483-016232-025469-031885_0_2_0_2_75_000_200.json (40/148)\n","처리 중: K-003483-019861-020238-028763_0_2_0_2_75_000_200.json (41/148)\n","처리 중: K-003483-022347-027653-036637_0_2_0_2_70_000_200.json (42/148)\n","처리 중: K-003351-020238-033880_0_2_0_2_75_000_200.json (43/148)\n","처리 중: K-003351-020238-033880_0_2_0_2_70_000_200.json (44/148)\n","처리 중: K-003483-027653-029667-031885_0_2_0_2_90_000_200.json (45/148)\n","처리 중: K-003483-027653-029667-031885_0_2_0_2_70_000_200.json (46/148)\n","처리 중: K-003351-021325-041768_0_2_0_2_90_000_200.json (47/148)\n","처리 중: K-003483-025469-029667-034597_0_2_0_2_75_000_200.json (48/148)\n","처리 중: K-003483-025469-029667-034597_0_2_0_2_90_000_200.json (49/148)\n","처리 중: K-003483-025367-025469-035206_0_2_0_2_90_000_200.json (50/148)\n","처리 중: K-002483-003743-004378-022627_0_2_0_2_75_000_200.json (51/148)\n","처리 중: K-003483-019861-034597-035206_0_2_0_2_90_000_200.json (52/148)\n","처리 중: K-003351-016688-032310_0_2_0_2_90_000_200.json (53/148)\n","처리 중: K-003544-010221-016548-027926_0_2_0_2_90_000_200.json (54/148)\n","처리 중: K-001900-016548-029345-033208_0_2_0_2_90_000_200.json (55/148)\n","처리 중: K-003483-016232-022347-025469_0_2_0_2_70_000_200.json (56/148)\n","처리 중: K-001900-016551-018110-029345_0_2_0_2_70_000_200.json (57/148)\n","처리 중: K-003483-020238-027777-030308_0_2_0_2_90_000_200.json (58/148)\n","처리 중: K-002483-003743-013395-022627_0_2_0_2_90_000_200.json (59/148)\n","처리 중: K-002483-003743-013395-023223_0_2_0_2_75_000_200.json (60/148)\n","처리 중: K-003483-025469-028763-035206_0_2_0_2_90_000_200.json (61/148)\n","처리 중: K-001900-016551-021026-024850_0_2_0_2_75_000_200.json (62/148)\n","처리 중: K-003483-016262-025367-025469_0_2_0_2_70_000_200.json (63/148)\n","처리 중: K-002483-022362-023223-025438_0_2_0_2_70_000_200.json (64/148)\n","처리 중: K-003351-019232-038162_0_2_0_2_75_000_200.json (65/148)\n","처리 중: K-003351-018147-036637_0_2_0_2_75_000_200.json (66/148)\n","처리 중: K-003351-018147-036637_0_2_0_2_70_000_200.json (67/148)\n","처리 중: K-002483-005094-006192-012081_0_2_0_2_90_000_200.json (68/148)\n","처리 중: K-002483-005094-006192-012081_0_2_0_2_75_000_200.json (69/148)\n","처리 중: K-003483-016262-027733-030308_0_2_0_2_70_000_200.json (70/148)\n","처리 중: K-003483-016262-027733-030308_0_2_0_2_75_000_200.json (71/148)\n","처리 중: K-003483-020238-027733-031885_0_2_0_2_70_000_200.json (72/148)\n","처리 중: K-003351-020238-032310_0_2_0_2_90_000_200.json (73/148)\n","처리 중: K-003351-031863-036637_0_2_0_2_75_000_200.json (74/148)\n","처리 중: K-003544-006563-012420-016551_0_2_0_2_90_000_200.json (75/148)\n","처리 중: K-002483-004378-019552-025438_0_2_0_2_75_000_200.json (76/148)\n","처리 중: K-002483-004378-019552-025438_0_2_0_2_70_000_200.json (77/148)\n","처리 중: K-003483-025469-031885-035206_0_2_0_2_70_000_200.json (78/148)\n","처리 중: K-003483-016232-027733-030308_0_2_0_2_75_000_200.json (79/148)\n","처리 중: K-003483-016232-027733-030308_0_2_0_2_90_000_200.json (80/148)\n","처리 중: K-003483-025469-034597-035206_0_2_0_2_90_000_200.json (81/148)\n","처리 중: K-003483-025367-027653-035206_0_2_0_2_90_000_200.json (82/148)\n","처리 중: K-002483-005094-013395-022627_0_2_0_2_70_000_200.json (83/148)\n","처리 중: K-003483-020238-025367-027733_0_2_0_2_70_000_200.json (84/148)\n","처리 중: K-002483-013395-022627-025438_0_2_0_2_90_000_200.json (85/148)\n","처리 중: K-002483-005886-022627-025438_0_2_0_2_90_000_200.json (86/148)\n","처리 중: K-002483-005886-022627-025438_0_2_0_2_70_000_200.json (87/148)\n","처리 중: K-002483-004378-006192-025438_0_2_0_2_90_000_200.json (88/148)\n","처리 중: K-003351-019232-036637_0_2_0_2_70_000_200.json (89/148)\n","처리 중: K-002483-003743-005886-022627_0_2_0_2_75_000_200.json (90/148)\n","처리 중: K-003483-016262-019861-025367_0_2_0_2_75_000_200.json (91/148)\n","처리 중: K-001900-016548-027926-033208_0_2_0_2_75_000_200.json (92/148)\n","처리 중: K-003544-006563-016551-029871_0_2_0_2_90_000_200.json (93/148)\n","처리 중: K-003483-027653-030308-035206_0_2_0_2_70_000_200.json (94/148)\n","처리 중: K-003483-020238-025469-034597_0_2_0_2_75_000_200.json (95/148)\n","처리 중: K-002483-004378-005094-006192_0_2_0_2_70_000_200.json (96/148)\n","처리 중: K-002483-006192-012081-025438_0_2_0_2_70_000_200.json (97/148)\n","처리 중: K-002483-006192-012081-025438_0_2_0_2_90_000_200.json (98/148)\n","처리 중: K-001900-016551-018110-031705_0_2_0_2_90_000_200.json (99/148)\n","처리 중: K-003483-020877-034597-035206_0_2_0_2_90_000_200.json (100/148)\n","처리 중: K-003351-018357-021325_0_2_0_2_90_000_200.json (101/148)\n","처리 중: K-003483-016262-027777-028763_0_2_0_2_90_000_200.json (102/148)\n","처리 중: K-003483-022347-025469-035206_0_2_0_2_70_000_200.json (103/148)\n","처리 중: K-003483-027733-034597-036637_0_2_0_2_90_000_200.json (104/148)\n","처리 중: K-003483-020238-027653-030308_0_2_0_2_70_000_200.json (105/148)\n","처리 중: K-003351-020014-020238_0_2_0_2_70_000_200.json (106/148)\n","처리 중: K-003483-016262-027653-030308_0_2_0_2_70_000_200.json (107/148)\n","처리 중: K-001900-016551-024850-029451_0_2_0_2_75_000_200.json (108/148)\n","처리 중: K-003351-003832-016262_0_2_0_2_90_000_200.json (109/148)\n","처리 중: K-003483-020877-031885-036637_0_2_0_2_90_000_200.json (110/148)\n","처리 중: K-003483-019861-020238-022347_0_2_0_2_90_000_200.json (111/148)\n","처리 중: K-001900-016548-018110-029345_0_2_0_2_75_000_200.json (112/148)\n","처리 중: K-003483-027733-029667-031885_0_2_0_2_70_000_200.json (113/148)\n","처리 중: K-002483-004378-012778-025438_0_2_0_2_70_000_200.json (114/148)\n","처리 중: K-003544-004543-016551-033878_0_2_0_2_90_000_200.json (115/148)\n","처리 중: K-003483-016232-025367-025469_0_2_0_2_90_000_200.json (116/148)\n","처리 중: K-003483-016232-025367-025469_0_2_0_2_75_000_200.json (117/148)\n","처리 중: K-003483-019861-034597-036637_0_2_0_2_70_000_200.json (118/148)\n","처리 중: K-003483-019861-028763-029667_0_2_0_2_90_000_200.json (119/148)\n","처리 중: K-001900-016548-033009-044199_0_2_0_2_75_000_200.json (120/148)\n","처리 중: K-003483-019861-030308-036637_0_2_0_2_90_000_200.json (121/148)\n","처리 중: K-001900-016551-027926-044199_0_2_0_2_70_000_200.json (122/148)\n","처리 중: K-001900-016551-027926-044199_0_2_0_2_75_000_200.json (123/148)\n","처리 중: K-003544-004543-016551-023203_0_2_0_2_75_000_200.json (124/148)\n","처리 중: K-003483-027777-028763-035206_0_2_0_2_70_000_200.json (125/148)\n","처리 중: K-003483-016232-020877-030308_0_2_0_2_90_000_200.json (126/148)\n","처리 중: K-001900-016548-021026-021771_0_2_0_2_90_000_200.json (127/148)\n","처리 중: K-001900-016548-019607-031705_0_2_0_2_70_000_200.json (128/148)\n","처리 중: K-003351-021325-031863_0_2_0_2_70_000_200.json (129/148)\n","처리 중: K-003351-032310-036637_0_2_0_2_75_000_200.json (130/148)\n","처리 중: K-002483-003743-006192-013395_0_2_0_2_75_000_200.json (131/148)\n","처리 중: K-002483-003743-006192-013395_0_2_0_2_90_000_200.json (132/148)\n","처리 중: K-003483-016232-025469-034597_0_2_0_2_75_000_200.json (133/148)\n","처리 중: K-002483-005886-023223-025438_0_2_0_2_70_000_200.json (134/148)\n","처리 중: K-003351-020014-022074_0_2_0_2_75_000_200.json (135/148)\n","처리 중: K-003483-027653-031885-035206_0_2_0_2_75_000_200.json (136/148)\n","처리 중: K-003483-027653-029667-030308_0_2_0_2_75_000_200.json (137/148)\n","처리 중: K-001900-016551-033009-044199_0_2_0_2_75_000_200.json (138/148)\n","처리 중: K-003544-010221-016548-029345_0_2_0_2_75_000_200.json (139/148)\n","처리 중: K-001900-016548-021771-027926_0_2_0_2_90_000_200.json (140/148)\n","처리 중: K-003483-019861-031885-036637_0_2_0_2_75_000_200.json (141/148)\n","처리 중: K-001900-016551-019607-029345_0_2_0_2_90_000_200.json (142/148)\n","처리 중: K-003351-013900-036637_0_2_0_2_90_000_200.json (143/148)\n","처리 중: K-003351-003832-035206_0_2_0_2_90_000_200.json (144/148)\n","처리 중: K-003351-035206-041768_0_2_0_2_70_000_200.json (145/148)\n","처리 중: K-002483-004378-005094-012778_0_2_0_2_75_000_200.json (146/148)\n","처리 중: K-003483-020877-022347-029667_0_2_0_2_75_000_200.json (147/148)\n","처리 중: K-003544-004543-010221-016551_0_2_0_2_90_000_200.json (148/148)\n","\n","병합 완료:\n","  - 이미지: 148개\n","  - 어노테이션: 148개\n","  - 카테고리: 28개\n","\n","=== 데이터 무결성 검증 ===\n","✓ 데이터 무결성 검증 통과!\n","이미지 파일들을 복사하는 중...\n","훈련 이미지 148개 복사 완료\n","테스트 이미지 843개 복사 완료\n","\n","데이터 분할 완료:\n","  훈련: 이미지 119개, 어노테이션 119개\n","  검증: 이미지 29개, 어노테이션 29개\n","\n","어노테이션 파일 저장 완료:\n","  - annotations_full.json: 전체 데이터\n","  - annotations_train.json: 훈련 분할\n","  - annotations_val.json: 검증 분할\n","\n","=== 데이터셋 통계 ===\n","총 이미지 수: 148\n","총 어노테이션 수: 148\n","총 카테고리 수: 28\n","\n","카테고리별 어노테이션 수 (알약 종류별 인스턴스 수):\n","  기넥신에프정(은행엽엑스)(수출용): 41개 인스턴스\n","  일양하이트린정 2mg: 24개 인스턴스\n","  뮤테란캡슐 100mg: 23개 인스턴스\n","  보령부스파정 5mg: 16개 인스턴스\n","  무코스타정(레바미피드)(비매품): 6개 인스턴스\n","  크레스토정 20mg: 4개 인스턴스\n","  노바스크정 5mg: 4개 인스턴스\n","  플라빅스정 75mg: 3개 인스턴스\n","  동아가바펜틴정 800mg: 3개 인스턴스\n","  카나브정 60mg: 2개 인스턴스\n","  리피로우정 20mg: 2개 인스턴스\n","  가바토파정 100mg: 2개 인스턴스\n","  리피토정 20mg: 2개 인스턴스\n","  제미메트서방정 50/1000mg: 2개 인스턴스\n","  리리카캡슐 150mg: 1개 인스턴스\n","  종근당글리아티린연질캡슐(콜린알포세레이트) : 1개 인스턴스\n","  자누비아정 50mg: 1개 인스턴스\n","  알드린정: 1개 인스턴스\n","  삐콤씨에프정 618.6mg/병: 1개 인스턴스\n","  아질렉트정(라사길린메실산염): 1개 인스턴스\n","  삼남건조수산화알루미늄겔정: 1개 인스턴스\n","  조인스정 200mg: 1개 인스턴스\n","  리렉스펜정 300mg/PTP: 1개 인스턴스\n","  트윈스타정 40/5mg: 1개 인스턴스\n","  세비카정 10/40mg: 1개 인스턴스\n","  쎄로켈정 100mg: 1개 인스턴스\n","  아토젯정 10/40mg: 1개 인스턴스\n","  엑스포지정 5/160mg: 1개 인스턴스\n","\n","이미지당 평균 객체 수: 1.00개\n","\n","이미지 크기 통계:\n","  너비: 최소 976, 최대 976, 평균 976.0\n","  높이: 최소 1280, 최대 1280, 평균 1280.0\n","\n","병합 완료! 결과는 './data/datasets/dataset_nano/processed' 디렉토리에 저장되었습니다.\n","\n","처리된 파일 구조:\n","./data/processed/\n","├── images/                    # 모든 훈련 이미지 파일\n","├── test_images/               # 테스트 이미지 (있는 경우)\n","├── annotations_full.json     # 전체 데이터\n","├── annotations_train.json    # 훈련 분할\n","└── annotations_val.json      # 검증 분할\n"]}]},{"cell_type":"code","source":["# 전역 설정 (권장) - 이 Colab 세션에서 계속 사용\n","!git config --global user.name \"Dongjin-1203\"\n","!git config --global user.email \"hambur1203@gmail.com\""],"metadata":{"id":"FhpRPVQfMghC","executionInfo":{"status":"ok","timestamp":1758189534040,"user_tz":-540,"elapsed":218,"user":{"displayName":"지동진","userId":"11099336268482278400"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJu_PEbOMiCY","executionInfo":{"status":"ok","timestamp":1758188335812,"user_tz":-540,"elapsed":47894,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"e0c8c2d2-6b86-4f1f-c8c1-5bafa3a51256"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["!git commit -m \"DETR모델을 위한 전처리 파일 생성 및 새로운 전처리 코드 노트북 작성\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osWsUmgUMj9T","executionInfo":{"status":"ok","timestamp":1758188337603,"user_tz":-540,"elapsed":1790,"user":{"displayName":"지동진","userId":"11099336268482278400"}},"outputId":"dbf784b1-77d4-487d-b54e-b1b8a9f2c632"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   notebooks/data_EDA.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mdata/datasets/\u001b[m\n","\t\u001b[31mdata_pipeline/notebooks/\u001b[m\n","\t\u001b[31mnotebooks/New_split_dataset.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git pull origin main"],"metadata":{"id":"DKtUQ3FMMlay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push origin main"],"metadata":{"id":"or6JhxHCMnA3"},"execution_count":null,"outputs":[]}]}